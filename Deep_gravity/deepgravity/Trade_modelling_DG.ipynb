{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook runs the Deep Gravity model on the yearly trade prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rgyuri/.pyenv/versions/3.10.2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "from torch import nn\n",
    "\n",
    "import model_utils\n",
    "from data_compiler import FlowDataset\n",
    "from deepgravity import DeepGravity\n",
    "\n",
    "sys.path.append('../trade_predictions')\n",
    "import parameters\n",
    "\n",
    "# random seeds\n",
    "torch.manual_seed(parameters.seed)\n",
    "np.random.seed(parameters.seed)\n",
    "random.seed(parameters.seed)\n",
    "\n",
    "torch_device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:01<00:00,  3.09s/it]\n",
      "100%|██████████| 20/20 [00:51<00:00,  2.56s/it]\n",
      "100%|██████████| 20/20 [00:00<00:00, 392.14it/s]\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Load data\n",
    "##############\n",
    "\n",
    "nodes = pd.read_csv(parameters.node_path)\n",
    "nodes_columns = parameters.node_features + [parameters.node_id] + [parameters.node_timestamp]\n",
    "nodes = nodes[nodes_columns]\n",
    "\n",
    "edges = pd.read_csv(parameters.edge_path)\n",
    "edges_columns = parameters.flows_features + [parameters.flow_origin] + \\\n",
    "    [parameters.flow_destination] + [parameters.flows_timestamp] + \\\n",
    "        [parameters.flows_value]\n",
    "edges = edges[edges_columns]\n",
    "\n",
    "##############\n",
    "# Initial cleaning\n",
    "##############\n",
    "\n",
    "nodes = nodes.fillna(0)\n",
    "\n",
    "##############\n",
    "# Create data objects\n",
    "##############\n",
    "\n",
    "columns = {'node_id': parameters.node_id,\n",
    "           'node_timestamp': parameters.node_timestamp,\n",
    "           'flow_origin': parameters.flow_origin,\n",
    "           'flow_destination': parameters.flow_destination,\n",
    "           'flows_timestamp': parameters.flows_timestamp,\n",
    "           'flows_value':parameters.flows_value}\n",
    "\n",
    "flow_data = FlowDataset(columns=columns,\n",
    "                        unit = [parameters.flow_origin, parameters.flows_timestamp],\n",
    "                        nodes=nodes,\n",
    "                        edges=edges,)\n",
    "\n",
    "# Create a list of FlowDataset objects\n",
    "flow_data_chunked = flow_data.create_chunks(chunk_size=6)\n",
    "\n",
    "# Add past values to each chunk\n",
    "[flow_chunk.add_past_values(periods=parameters.lag_periods,\n",
    "                            edge_columns = parameters.time_dependent_edge_columns,\n",
    "                            node_columns = parameters.time_dependent_node_columns) for flow_chunk in tqdm.tqdm(flow_data_chunked)]\n",
    "\n",
    "# Add target to each chunk\n",
    "[flow_chunk.add_target_values() for flow_chunk in tqdm.tqdm(flow_data_chunked)]\n",
    "\n",
    "# Create a list of FlowDataset objects\n",
    "train_data_chunked = []\n",
    "test_data_chunked = []\n",
    "\n",
    "for flow_data in tqdm.tqdm(flow_data_chunked):\n",
    "    train_data, test_data = flow_data.split_train_test(test_period = 1)\n",
    "    train_data_chunked.append(train_data)\n",
    "    test_data_chunked.append(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 249872096.000000  [   10/  258]\n",
      "loss: 166969216.000000  [  110/  258]\n",
      "loss: 68005112.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2416031.333333 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 42864516.000000  [   10/  258]\n",
      "loss: 63920668.000000  [  110/  258]\n",
      "loss: 72086968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1652146.138889 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 134415008.000000  [   10/  258]\n",
      "loss: 93359896.000000  [  110/  258]\n",
      "loss: 34570000.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1168637.625000 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 60600500.000000  [   10/  258]\n",
      "loss: 46320940.000000  [  110/  258]\n",
      "loss: 159644672.000000  [  210/  258]\n",
      "Test Error: Avg loss: 812213.875000 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 39048920.000000  [   10/  258]\n",
      "loss: 55640260.000000  [  110/  258]\n",
      "loss: 84760536.000000  [  210/  258]\n",
      "Test Error: Avg loss: 677874.975694 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 62548344.000000  [   10/  258]\n",
      "loss: 48159624.000000  [  110/  258]\n",
      "loss: 21305100.000000  [  210/  258]\n",
      "Test Error: Avg loss: 556000.600694 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 50779096.000000  [   10/  258]\n",
      "loss: 17761002.000000  [  110/  258]\n",
      "loss: 24214292.000000  [  210/  258]\n",
      "Test Error: Avg loss: 481208.973958 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 57522872.000000  [   10/  258]\n",
      "loss: 30332664.000000  [  110/  258]\n",
      "loss: 23279504.000000  [  210/  258]\n",
      "Test Error: Avg loss: 436939.623264 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 52928452.000000  [   10/  258]\n",
      "loss: 51472304.000000  [  110/  258]\n",
      "loss: 36525960.000000  [  210/  258]\n",
      "Test Error: Avg loss: 336474.456597 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 101272528.000000  [   10/  258]\n",
      "loss: 32387668.000000  [  110/  258]\n",
      "loss: 26862168.000000  [  210/  258]\n",
      "Test Error: Avg loss: 234705.822917 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 22667564.000000  [   10/  258]\n",
      "loss: 31409846.000000  [  110/  258]\n",
      "loss: 46711656.000000  [  210/  258]\n",
      "Test Error: Avg loss: 197568.456597 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 45556292.000000  [   10/  258]\n",
      "loss: 25595336.000000  [  110/  258]\n",
      "loss: 16735976.000000  [  210/  258]\n",
      "Test Error: Avg loss: 149477.414931 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 36139984.000000  [   10/  258]\n",
      "loss: 31905096.000000  [  110/  258]\n",
      "loss: 45401424.000000  [  210/  258]\n",
      "Test Error: Avg loss: 140409.906250 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 64394172.000000  [   10/  258]\n",
      "loss: 48456700.000000  [  110/  258]\n",
      "loss: 13728254.000000  [  210/  258]\n",
      "Test Error: Avg loss: 84518.854167 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 31929780.000000  [   10/  258]\n",
      "loss: 29274740.000000  [  110/  258]\n",
      "loss: 27862864.000000  [  210/  258]\n",
      "Test Error: Avg loss: 63265.355035 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 45285808.000000  [   10/  258]\n",
      "loss: 26924404.000000  [  110/  258]\n",
      "loss: 27975020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 36953.542969 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 35053548.000000  [   10/  258]\n",
      "loss: 34364460.000000  [  110/  258]\n",
      "loss: 21750692.000000  [  210/  258]\n",
      "Test Error: Avg loss: 35366.512153 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 17043106.000000  [   10/  258]\n",
      "loss: 8752048.000000  [  110/  258]\n",
      "loss: 49561104.000000  [  210/  258]\n",
      "Test Error: Avg loss: 29738.236545 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 12928062.000000  [   10/  258]\n",
      "loss: 39132728.000000  [  110/  258]\n",
      "loss: 15192385.000000  [  210/  258]\n",
      "Test Error: Avg loss: 31267.462023 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 10896246.000000  [   10/  258]\n",
      "loss: 13420572.000000  [  110/  258]\n",
      "loss: 15485511.000000  [  210/  258]\n",
      "Test Error: Avg loss: 35446.777127 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 26324840.000000  [   10/  258]\n",
      "loss: 14947315.000000  [  110/  258]\n",
      "loss: 20450212.000000  [  210/  258]\n",
      "Test Error: Avg loss: 33867.998481 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 18985506.000000  [   10/  258]\n",
      "loss: 21852408.000000  [  110/  258]\n",
      "loss: 13901807.000000  [  210/  258]\n",
      "Test Error: Avg loss: 31578.390625 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 10461682.000000  [   10/  258]\n",
      "loss: 12147058.000000  [  110/  258]\n",
      "loss: 3927331.000000  [  210/  258]\n",
      "Test Error: Avg loss: 17718.740234 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 9323320.000000  [   10/  258]\n",
      "loss: 9641276.000000  [  110/  258]\n",
      "loss: 14562807.000000  [  210/  258]\n",
      "Test Error: Avg loss: 16732.255859 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 13461810.000000  [   10/  258]\n",
      "loss: 26425220.000000  [  110/  258]\n",
      "loss: 7927126.000000  [  210/  258]\n",
      "Test Error: Avg loss: 10990.914171 \n",
      "\n",
      "Test Error: Avg loss: 10990.914171 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 184003568.000000  [   10/  258]\n",
      "loss: 243174400.000000  [  110/  258]\n",
      "loss: 68102864.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1958871.027778 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 181903168.000000  [   10/  258]\n",
      "loss: 107183984.000000  [  110/  258]\n",
      "loss: 75654184.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1435069.527778 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 171856368.000000  [   10/  258]\n",
      "loss: 115588544.000000  [  110/  258]\n",
      "loss: 61474120.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1297045.770833 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 97105448.000000  [   10/  258]\n",
      "loss: 48579632.000000  [  110/  258]\n",
      "loss: 88184368.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1067205.708333 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 83394184.000000  [   10/  258]\n",
      "loss: 50640320.000000  [  110/  258]\n",
      "loss: 20749350.000000  [  210/  258]\n",
      "Test Error: Avg loss: 931389.756944 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 65164504.000000  [   10/  258]\n",
      "loss: 100111216.000000  [  110/  258]\n",
      "loss: 82163400.000000  [  210/  258]\n",
      "Test Error: Avg loss: 712409.895833 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 50678576.000000  [   10/  258]\n",
      "loss: 21461314.000000  [  110/  258]\n",
      "loss: 64683560.000000  [  210/  258]\n",
      "Test Error: Avg loss: 669032.086806 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 48083248.000000  [   10/  258]\n",
      "loss: 45268828.000000  [  110/  258]\n",
      "loss: 78816288.000000  [  210/  258]\n",
      "Test Error: Avg loss: 527845.048611 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 55794224.000000  [   10/  258]\n",
      "loss: 48111052.000000  [  110/  258]\n",
      "loss: 16778888.000000  [  210/  258]\n",
      "Test Error: Avg loss: 238252.364583 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 46679888.000000  [   10/  258]\n",
      "loss: 84083304.000000  [  110/  258]\n",
      "loss: 23905246.000000  [  210/  258]\n",
      "Test Error: Avg loss: 162365.012153 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 36895856.000000  [   10/  258]\n",
      "loss: 39482728.000000  [  110/  258]\n",
      "loss: 24075592.000000  [  210/  258]\n",
      "Test Error: Avg loss: 149567.291667 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 51755332.000000  [   10/  258]\n",
      "loss: 16587155.000000  [  110/  258]\n",
      "loss: 15691134.000000  [  210/  258]\n",
      "Test Error: Avg loss: 161043.449653 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 38138268.000000  [   10/  258]\n",
      "loss: 36945980.000000  [  110/  258]\n",
      "loss: 35123364.000000  [  210/  258]\n",
      "Test Error: Avg loss: 178434.995660 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 11264324.000000  [   10/  258]\n",
      "loss: 34262956.000000  [  110/  258]\n",
      "loss: 19706152.000000  [  210/  258]\n",
      "Test Error: Avg loss: 141040.795139 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 25702470.000000  [   10/  258]\n",
      "loss: 28090906.000000  [  110/  258]\n",
      "loss: 16381680.000000  [  210/  258]\n",
      "Test Error: Avg loss: 136574.949653 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 22408038.000000  [   10/  258]\n",
      "loss: 32313730.000000  [  110/  258]\n",
      "loss: 37111264.000000  [  210/  258]\n",
      "Test Error: Avg loss: 125002.361111 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 18408584.000000  [   10/  258]\n",
      "loss: 19877606.000000  [  110/  258]\n",
      "loss: 25317944.000000  [  210/  258]\n",
      "Test Error: Avg loss: 105173.059896 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 18799640.000000  [   10/  258]\n",
      "loss: 20887806.000000  [  110/  258]\n",
      "loss: 31481064.000000  [  210/  258]\n",
      "Test Error: Avg loss: 86003.502170 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 12604271.000000  [   10/  258]\n",
      "loss: 12741730.000000  [  110/  258]\n",
      "loss: 12720342.000000  [  210/  258]\n",
      "Test Error: Avg loss: 83799.335503 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 41476168.000000  [   10/  258]\n",
      "loss: 19375580.000000  [  110/  258]\n",
      "loss: 16342941.000000  [  210/  258]\n",
      "Test Error: Avg loss: 71374.505642 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 15487591.000000  [   10/  258]\n",
      "loss: 16859382.000000  [  110/  258]\n",
      "loss: 19368082.000000  [  210/  258]\n",
      "Test Error: Avg loss: 82296.249566 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 11368325.000000  [   10/  258]\n",
      "loss: 12526866.000000  [  110/  258]\n",
      "loss: 18263806.000000  [  210/  258]\n",
      "Test Error: Avg loss: 56939.868490 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 17105532.000000  [   10/  258]\n",
      "loss: 19502648.000000  [  110/  258]\n",
      "loss: 10880488.000000  [  210/  258]\n",
      "Test Error: Avg loss: 49239.528863 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 20330448.000000  [   10/  258]\n",
      "loss: 24053868.000000  [  110/  258]\n",
      "loss: 11281582.000000  [  210/  258]\n",
      "Test Error: Avg loss: 25194.139323 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 16648674.000000  [   10/  258]\n",
      "loss: 18314664.000000  [  110/  258]\n",
      "loss: 10027055.000000  [  210/  258]\n",
      "Test Error: Avg loss: 32904.931858 \n",
      "\n",
      "Test Error: Avg loss: 32904.931858 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 572976128.000000  [   10/  258]\n",
      "loss: 263379520.000000  [  110/  258]\n",
      "loss: 206481840.000000  [  210/  258]\n",
      "Test Error: Avg loss: 3636517.666667 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 204912176.000000  [   10/  258]\n",
      "loss: 125755024.000000  [  110/  258]\n",
      "loss: 204893648.000000  [  210/  258]\n",
      "Test Error: Avg loss: 494054.322917 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 143894080.000000  [   10/  258]\n",
      "loss: 196336896.000000  [  110/  258]\n",
      "loss: 92433968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181341.706597 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 130064496.000000  [   10/  258]\n",
      "loss: 99815248.000000  [  110/  258]\n",
      "loss: 70957608.000000  [  210/  258]\n",
      "Test Error: Avg loss: 97739.851128 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 77241616.000000  [   10/  258]\n",
      "loss: 107285040.000000  [  110/  258]\n",
      "loss: 54407212.000000  [  210/  258]\n",
      "Test Error: Avg loss: 72502.432726 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 62095336.000000  [   10/  258]\n",
      "loss: 82709872.000000  [  110/  258]\n",
      "loss: 84393608.000000  [  210/  258]\n",
      "Test Error: Avg loss: 87317.802083 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 104166200.000000  [   10/  258]\n",
      "loss: 125491456.000000  [  110/  258]\n",
      "loss: 56837928.000000  [  210/  258]\n",
      "Test Error: Avg loss: 254816.496528 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 83871656.000000  [   10/  258]\n",
      "loss: 86404392.000000  [  110/  258]\n",
      "loss: 56472576.000000  [  210/  258]\n",
      "Test Error: Avg loss: 269209.685764 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 75064736.000000  [   10/  258]\n",
      "loss: 99200592.000000  [  110/  258]\n",
      "loss: 52663104.000000  [  210/  258]\n",
      "Test Error: Avg loss: 188750.142361 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 92590664.000000  [   10/  258]\n",
      "loss: 25319508.000000  [  110/  258]\n",
      "loss: 51744160.000000  [  210/  258]\n",
      "Test Error: Avg loss: 103734.757812 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 88580768.000000  [   10/  258]\n",
      "loss: 75577688.000000  [  110/  258]\n",
      "loss: 40961668.000000  [  210/  258]\n",
      "Test Error: Avg loss: 56566.980469 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 61383536.000000  [   10/  258]\n",
      "loss: 38762688.000000  [  110/  258]\n",
      "loss: 51771232.000000  [  210/  258]\n",
      "Test Error: Avg loss: 115917.516493 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 74058144.000000  [   10/  258]\n",
      "loss: 73407376.000000  [  110/  258]\n",
      "loss: 35153184.000000  [  210/  258]\n",
      "Test Error: Avg loss: 70636.411241 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 103933680.000000  [   10/  258]\n",
      "loss: 40060108.000000  [  110/  258]\n",
      "loss: 78677488.000000  [  210/  258]\n",
      "Test Error: Avg loss: 59266.091580 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 69026000.000000  [   10/  258]\n",
      "loss: 53512208.000000  [  110/  258]\n",
      "loss: 45558080.000000  [  210/  258]\n",
      "Test Error: Avg loss: 134590.988715 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 26861022.000000  [   10/  258]\n",
      "loss: 43577080.000000  [  110/  258]\n",
      "loss: 25749346.000000  [  210/  258]\n",
      "Test Error: Avg loss: 152775.051215 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 28129976.000000  [   10/  258]\n",
      "loss: 27363984.000000  [  110/  258]\n",
      "loss: 53532160.000000  [  210/  258]\n",
      "Test Error: Avg loss: 137003.436632 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 35085552.000000  [   10/  258]\n",
      "loss: 51796272.000000  [  110/  258]\n",
      "loss: 24385090.000000  [  210/  258]\n",
      "Test Error: Avg loss: 116460.721354 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 45697232.000000  [   10/  258]\n",
      "loss: 71397424.000000  [  110/  258]\n",
      "loss: 27554370.000000  [  210/  258]\n",
      "Test Error: Avg loss: 97110.991319 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 51597224.000000  [   10/  258]\n",
      "loss: 44874096.000000  [  110/  258]\n",
      "loss: 16296155.000000  [  210/  258]\n",
      "Test Error: Avg loss: 88448.157118 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 37085512.000000  [   10/  258]\n",
      "loss: 34348660.000000  [  110/  258]\n",
      "loss: 24129188.000000  [  210/  258]\n",
      "Test Error: Avg loss: 55505.294705 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 24359408.000000  [   10/  258]\n",
      "loss: 36678624.000000  [  110/  258]\n",
      "loss: 25949592.000000  [  210/  258]\n",
      "Test Error: Avg loss: 35371.388889 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 33927508.000000  [   10/  258]\n",
      "loss: 33291944.000000  [  110/  258]\n",
      "loss: 44261704.000000  [  210/  258]\n",
      "Test Error: Avg loss: 27266.546658 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 13450022.000000  [   10/  258]\n",
      "loss: 32284872.000000  [  110/  258]\n",
      "loss: 20866972.000000  [  210/  258]\n",
      "Test Error: Avg loss: 34150.289931 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 40268312.000000  [   10/  258]\n",
      "loss: 32856084.000000  [  110/  258]\n",
      "loss: 18996816.000000  [  210/  258]\n",
      "Test Error: Avg loss: 23763.343099 \n",
      "\n",
      "Test Error: Avg loss: 23763.343099 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 199880240.000000  [   10/  258]\n",
      "loss: 294723264.000000  [  110/  258]\n",
      "loss: 184436352.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1655316.638889 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 165191232.000000  [   10/  258]\n",
      "loss: 91298896.000000  [  110/  258]\n",
      "loss: 173311824.000000  [  210/  258]\n",
      "Test Error: Avg loss: 782083.895833 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 151212624.000000  [   10/  258]\n",
      "loss: 120584576.000000  [  110/  258]\n",
      "loss: 130803648.000000  [  210/  258]\n",
      "Test Error: Avg loss: 419221.340278 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 225992096.000000  [   10/  258]\n",
      "loss: 81898512.000000  [  110/  258]\n",
      "loss: 78930488.000000  [  210/  258]\n",
      "Test Error: Avg loss: 365382.493056 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 108576512.000000  [   10/  258]\n",
      "loss: 150305232.000000  [  110/  258]\n",
      "loss: 37812160.000000  [  210/  258]\n",
      "Test Error: Avg loss: 220205.975694 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 75689440.000000  [   10/  258]\n",
      "loss: 31498774.000000  [  110/  258]\n",
      "loss: 31486750.000000  [  210/  258]\n",
      "Test Error: Avg loss: 134374.025174 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 67875048.000000  [   10/  258]\n",
      "loss: 86362560.000000  [  110/  258]\n",
      "loss: 40050532.000000  [  210/  258]\n",
      "Test Error: Avg loss: 149643.486979 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 35532220.000000  [   10/  258]\n",
      "loss: 67932336.000000  [  110/  258]\n",
      "loss: 28994950.000000  [  210/  258]\n",
      "Test Error: Avg loss: 93714.144965 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 38785980.000000  [   10/  258]\n",
      "loss: 32173268.000000  [  110/  258]\n",
      "loss: 37199900.000000  [  210/  258]\n",
      "Test Error: Avg loss: 164991.666667 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 25962210.000000  [   10/  258]\n",
      "loss: 56774348.000000  [  110/  258]\n",
      "loss: 32435052.000000  [  210/  258]\n",
      "Test Error: Avg loss: 168422.475694 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 41933896.000000  [   10/  258]\n",
      "loss: 83962368.000000  [  110/  258]\n",
      "loss: 20334140.000000  [  210/  258]\n",
      "Test Error: Avg loss: 134390.238715 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 46772856.000000  [   10/  258]\n",
      "loss: 45403160.000000  [  110/  258]\n",
      "loss: 30087096.000000  [  210/  258]\n",
      "Test Error: Avg loss: 65101.616319 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 30030626.000000  [   10/  258]\n",
      "loss: 28641092.000000  [  110/  258]\n",
      "loss: 41833196.000000  [  210/  258]\n",
      "Test Error: Avg loss: 80284.457899 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 26590018.000000  [   10/  258]\n",
      "loss: 21856248.000000  [  110/  258]\n",
      "loss: 17240894.000000  [  210/  258]\n",
      "Test Error: Avg loss: 89929.805556 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 28852742.000000  [   10/  258]\n",
      "loss: 36238528.000000  [  110/  258]\n",
      "loss: 44096432.000000  [  210/  258]\n",
      "Test Error: Avg loss: 63198.240885 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 29994286.000000  [   10/  258]\n",
      "loss: 20079050.000000  [  110/  258]\n",
      "loss: 32075282.000000  [  210/  258]\n",
      "Test Error: Avg loss: 93679.526910 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 22698536.000000  [   10/  258]\n",
      "loss: 17923792.000000  [  110/  258]\n",
      "loss: 12701968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 100521.361979 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 19370190.000000  [   10/  258]\n",
      "loss: 30867100.000000  [  110/  258]\n",
      "loss: 11117728.000000  [  210/  258]\n",
      "Test Error: Avg loss: 68504.241319 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 21392316.000000  [   10/  258]\n",
      "loss: 25262700.000000  [  110/  258]\n",
      "loss: 18122156.000000  [  210/  258]\n",
      "Test Error: Avg loss: 52617.288194 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 15036168.000000  [   10/  258]\n",
      "loss: 22736020.000000  [  110/  258]\n",
      "loss: 35330836.000000  [  210/  258]\n",
      "Test Error: Avg loss: 44173.551649 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 16003534.000000  [   10/  258]\n",
      "loss: 17539196.000000  [  110/  258]\n",
      "loss: 16177302.000000  [  210/  258]\n",
      "Test Error: Avg loss: 25359.771050 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 10603692.000000  [   10/  258]\n",
      "loss: 16562128.000000  [  110/  258]\n",
      "loss: 15375128.000000  [  210/  258]\n",
      "Test Error: Avg loss: 22543.787760 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 11495000.000000  [   10/  258]\n",
      "loss: 19086810.000000  [  110/  258]\n",
      "loss: 14767959.000000  [  210/  258]\n",
      "Test Error: Avg loss: 24517.530382 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 13530360.000000  [   10/  258]\n",
      "loss: 19197692.000000  [  110/  258]\n",
      "loss: 12082681.000000  [  210/  258]\n",
      "Test Error: Avg loss: 25654.492622 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 20308640.000000  [   10/  258]\n",
      "loss: 16612714.000000  [  110/  258]\n",
      "loss: 14280766.000000  [  210/  258]\n",
      "Test Error: Avg loss: 12369.108724 \n",
      "\n",
      "Test Error: Avg loss: 12369.108724 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 422958592.000000  [   10/  258]\n",
      "loss: 235848768.000000  [  110/  258]\n",
      "loss: 175869584.000000  [  210/  258]\n",
      "Test Error: Avg loss: 8864635.902778 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 211499744.000000  [   10/  258]\n",
      "loss: 167691904.000000  [  110/  258]\n",
      "loss: 42184704.000000  [  210/  258]\n",
      "Test Error: Avg loss: 4299097.902778 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 388482688.000000  [   10/  258]\n",
      "loss: 114902552.000000  [  110/  258]\n",
      "loss: 31147852.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2630567.541667 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 135081568.000000  [   10/  258]\n",
      "loss: 128461680.000000  [  110/  258]\n",
      "loss: 33182180.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1795311.270833 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 85172552.000000  [   10/  258]\n",
      "loss: 97327456.000000  [  110/  258]\n",
      "loss: 31767638.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1215788.826389 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 86096232.000000  [   10/  258]\n",
      "loss: 121227488.000000  [  110/  258]\n",
      "loss: 35160580.000000  [  210/  258]\n",
      "Test Error: Avg loss: 826189.930556 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 70736208.000000  [   10/  258]\n",
      "loss: 140300624.000000  [  110/  258]\n",
      "loss: 18708406.000000  [  210/  258]\n",
      "Test Error: Avg loss: 484633.329861 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 78836280.000000  [   10/  258]\n",
      "loss: 80364744.000000  [  110/  258]\n",
      "loss: 11443255.000000  [  210/  258]\n",
      "Test Error: Avg loss: 412879.515625 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 72026352.000000  [   10/  258]\n",
      "loss: 36471508.000000  [  110/  258]\n",
      "loss: 29812984.000000  [  210/  258]\n",
      "Test Error: Avg loss: 326067.800347 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 95631944.000000  [   10/  258]\n",
      "loss: 44568244.000000  [  110/  258]\n",
      "loss: 10486434.000000  [  210/  258]\n",
      "Test Error: Avg loss: 289714.894965 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 67017704.000000  [   10/  258]\n",
      "loss: 53612952.000000  [  110/  258]\n",
      "loss: 17939838.000000  [  210/  258]\n",
      "Test Error: Avg loss: 253902.197049 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 49742040.000000  [   10/  258]\n",
      "loss: 68609072.000000  [  110/  258]\n",
      "loss: 13813191.000000  [  210/  258]\n",
      "Test Error: Avg loss: 194652.311198 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 45882456.000000  [   10/  258]\n",
      "loss: 54183880.000000  [  110/  258]\n",
      "loss: 10242235.000000  [  210/  258]\n",
      "Test Error: Avg loss: 199190.574219 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 18425602.000000  [   10/  258]\n",
      "loss: 52279080.000000  [  110/  258]\n",
      "loss: 13179974.000000  [  210/  258]\n",
      "Test Error: Avg loss: 198504.046007 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 58687872.000000  [   10/  258]\n",
      "loss: 25465164.000000  [  110/  258]\n",
      "loss: 27040300.000000  [  210/  258]\n",
      "Test Error: Avg loss: 186853.564670 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 22412292.000000  [   10/  258]\n",
      "loss: 33886712.000000  [  110/  258]\n",
      "loss: 15408544.000000  [  210/  258]\n",
      "Test Error: Avg loss: 170363.311632 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 30786808.000000  [   10/  258]\n",
      "loss: 21668552.000000  [  110/  258]\n",
      "loss: 20550118.000000  [  210/  258]\n",
      "Test Error: Avg loss: 153475.934896 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 17457416.000000  [   10/  258]\n",
      "loss: 22707044.000000  [  110/  258]\n",
      "loss: 11796512.000000  [  210/  258]\n",
      "Test Error: Avg loss: 141354.756944 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 24161652.000000  [   10/  258]\n",
      "loss: 13289119.000000  [  110/  258]\n",
      "loss: 8945084.000000  [  210/  258]\n",
      "Test Error: Avg loss: 113107.489583 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 30397240.000000  [   10/  258]\n",
      "loss: 36436180.000000  [  110/  258]\n",
      "loss: 17903126.000000  [  210/  258]\n",
      "Test Error: Avg loss: 138312.780382 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 17589708.000000  [   10/  258]\n",
      "loss: 25949402.000000  [  110/  258]\n",
      "loss: 9376853.000000  [  210/  258]\n",
      "Test Error: Avg loss: 130305.805556 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 13386297.000000  [   10/  258]\n",
      "loss: 10520151.000000  [  110/  258]\n",
      "loss: 16670100.000000  [  210/  258]\n",
      "Test Error: Avg loss: 110217.097222 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 12175868.000000  [   10/  258]\n",
      "loss: 15600490.000000  [  110/  258]\n",
      "loss: 11427758.000000  [  210/  258]\n",
      "Test Error: Avg loss: 92350.545573 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 41625092.000000  [   10/  258]\n",
      "loss: 31667382.000000  [  110/  258]\n",
      "loss: 10219922.000000  [  210/  258]\n",
      "Test Error: Avg loss: 75068.318576 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 17779484.000000  [   10/  258]\n",
      "loss: 6892987.500000  [  110/  258]\n",
      "loss: 7291539.000000  [  210/  258]\n",
      "Test Error: Avg loss: 46900.695964 \n",
      "\n",
      "Test Error: Avg loss: 46900.695964 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 390481216.000000  [   10/  258]\n",
      "loss: 201300704.000000  [  110/  258]\n",
      "loss: 291175008.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1002659.335069 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 152546944.000000  [   10/  258]\n",
      "loss: 291976736.000000  [  110/  258]\n",
      "loss: 93551760.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1042477.593750 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 138327456.000000  [   10/  258]\n",
      "loss: 53578612.000000  [  110/  258]\n",
      "loss: 106518176.000000  [  210/  258]\n",
      "Test Error: Avg loss: 913720.286458 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 92898200.000000  [   10/  258]\n",
      "loss: 66900776.000000  [  110/  258]\n",
      "loss: 44257416.000000  [  210/  258]\n",
      "Test Error: Avg loss: 731294.392361 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 42003736.000000  [   10/  258]\n",
      "loss: 76164488.000000  [  110/  258]\n",
      "loss: 29881484.000000  [  210/  258]\n",
      "Test Error: Avg loss: 695802.173611 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 100164664.000000  [   10/  258]\n",
      "loss: 110904368.000000  [  110/  258]\n",
      "loss: 121942784.000000  [  210/  258]\n",
      "Test Error: Avg loss: 667190.904514 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 107954376.000000  [   10/  258]\n",
      "loss: 41875496.000000  [  110/  258]\n",
      "loss: 55540508.000000  [  210/  258]\n",
      "Test Error: Avg loss: 648744.055556 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 73535152.000000  [   10/  258]\n",
      "loss: 33277750.000000  [  110/  258]\n",
      "loss: 37168884.000000  [  210/  258]\n",
      "Test Error: Avg loss: 578911.496528 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 67906440.000000  [   10/  258]\n",
      "loss: 60483180.000000  [  110/  258]\n",
      "loss: 43804392.000000  [  210/  258]\n",
      "Test Error: Avg loss: 511882.746528 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 64212128.000000  [   10/  258]\n",
      "loss: 63028780.000000  [  110/  258]\n",
      "loss: 62820564.000000  [  210/  258]\n",
      "Test Error: Avg loss: 450617.623264 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 30832638.000000  [   10/  258]\n",
      "loss: 39867432.000000  [  110/  258]\n",
      "loss: 53033824.000000  [  210/  258]\n",
      "Test Error: Avg loss: 503734.661458 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 73415544.000000  [   10/  258]\n",
      "loss: 64450928.000000  [  110/  258]\n",
      "loss: 26750252.000000  [  210/  258]\n",
      "Test Error: Avg loss: 522918.005208 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 36335980.000000  [   10/  258]\n",
      "loss: 43538060.000000  [  110/  258]\n",
      "loss: 56346632.000000  [  210/  258]\n",
      "Test Error: Avg loss: 467117.294271 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 36517864.000000  [   10/  258]\n",
      "loss: 16665086.000000  [  110/  258]\n",
      "loss: 25704868.000000  [  210/  258]\n",
      "Test Error: Avg loss: 401493.736111 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 57358324.000000  [   10/  258]\n",
      "loss: 59222580.000000  [  110/  258]\n",
      "loss: 35907180.000000  [  210/  258]\n",
      "Test Error: Avg loss: 334338.980035 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 22640926.000000  [   10/  258]\n",
      "loss: 49669436.000000  [  110/  258]\n",
      "loss: 19312920.000000  [  210/  258]\n",
      "Test Error: Avg loss: 310184.954861 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 67244816.000000  [   10/  258]\n",
      "loss: 23884046.000000  [  110/  258]\n",
      "loss: 60265080.000000  [  210/  258]\n",
      "Test Error: Avg loss: 284740.067708 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 25618236.000000  [   10/  258]\n",
      "loss: 31918488.000000  [  110/  258]\n",
      "loss: 26709356.000000  [  210/  258]\n",
      "Test Error: Avg loss: 253083.407118 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 26423950.000000  [   10/  258]\n",
      "loss: 37819648.000000  [  110/  258]\n",
      "loss: 27357596.000000  [  210/  258]\n",
      "Test Error: Avg loss: 264885.407118 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 59901400.000000  [   10/  258]\n",
      "loss: 40080944.000000  [  110/  258]\n",
      "loss: 22855572.000000  [  210/  258]\n",
      "Test Error: Avg loss: 231771.091580 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 31493676.000000  [   10/  258]\n",
      "loss: 44376480.000000  [  110/  258]\n",
      "loss: 19026786.000000  [  210/  258]\n",
      "Test Error: Avg loss: 205507.447049 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 39011848.000000  [   10/  258]\n",
      "loss: 22561980.000000  [  110/  258]\n",
      "loss: 17086810.000000  [  210/  258]\n",
      "Test Error: Avg loss: 155212.211806 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 17417060.000000  [   10/  258]\n",
      "loss: 30207540.000000  [  110/  258]\n",
      "loss: 24916280.000000  [  210/  258]\n",
      "Test Error: Avg loss: 131704.835069 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 23565600.000000  [   10/  258]\n",
      "loss: 29216212.000000  [  110/  258]\n",
      "loss: 19993494.000000  [  210/  258]\n",
      "Test Error: Avg loss: 116999.722222 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 24896730.000000  [   10/  258]\n",
      "loss: 11784076.000000  [  110/  258]\n",
      "loss: 47277760.000000  [  210/  258]\n",
      "Test Error: Avg loss: 101639.957465 \n",
      "\n",
      "Test Error: Avg loss: 101639.957465 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 246933408.000000  [   10/  258]\n",
      "loss: 326706496.000000  [  110/  258]\n",
      "loss: 157983616.000000  [  210/  258]\n",
      "Test Error: Avg loss: 224241.926215 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 135146016.000000  [   10/  258]\n",
      "loss: 107351736.000000  [  110/  258]\n",
      "loss: 197354624.000000  [  210/  258]\n",
      "Test Error: Avg loss: 387889.921875 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 75459064.000000  [   10/  258]\n",
      "loss: 94844816.000000  [  110/  258]\n",
      "loss: 67736352.000000  [  210/  258]\n",
      "Test Error: Avg loss: 443827.003472 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 131901552.000000  [   10/  258]\n",
      "loss: 113975328.000000  [  110/  258]\n",
      "loss: 121204624.000000  [  210/  258]\n",
      "Test Error: Avg loss: 370835.418403 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 42619804.000000  [   10/  258]\n",
      "loss: 63764408.000000  [  110/  258]\n",
      "loss: 38896964.000000  [  210/  258]\n",
      "Test Error: Avg loss: 297239.980903 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 113360792.000000  [   10/  258]\n",
      "loss: 33947888.000000  [  110/  258]\n",
      "loss: 35766396.000000  [  210/  258]\n",
      "Test Error: Avg loss: 236433.813368 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 81108640.000000  [   10/  258]\n",
      "loss: 57607560.000000  [  110/  258]\n",
      "loss: 45325608.000000  [  210/  258]\n",
      "Test Error: Avg loss: 115789.278646 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 110783472.000000  [   10/  258]\n",
      "loss: 62398508.000000  [  110/  258]\n",
      "loss: 57496092.000000  [  210/  258]\n",
      "Test Error: Avg loss: 27079.462891 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 62718712.000000  [   10/  258]\n",
      "loss: 37694648.000000  [  110/  258]\n",
      "loss: 31784954.000000  [  210/  258]\n",
      "Test Error: Avg loss: 58637.809896 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 25365760.000000  [   10/  258]\n",
      "loss: 82321144.000000  [  110/  258]\n",
      "loss: 34023476.000000  [  210/  258]\n",
      "Test Error: Avg loss: 25960.719618 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 17142036.000000  [   10/  258]\n",
      "loss: 34650352.000000  [  110/  258]\n",
      "loss: 30320778.000000  [  210/  258]\n",
      "Test Error: Avg loss: 71246.745660 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 26150780.000000  [   10/  258]\n",
      "loss: 40644328.000000  [  110/  258]\n",
      "loss: 60815216.000000  [  210/  258]\n",
      "Test Error: Avg loss: 23096.877062 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 16022433.000000  [   10/  258]\n",
      "loss: 47068268.000000  [  110/  258]\n",
      "loss: 27407010.000000  [  210/  258]\n",
      "Test Error: Avg loss: 89277.747396 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 21409504.000000  [   10/  258]\n",
      "loss: 64138384.000000  [  110/  258]\n",
      "loss: 23782830.000000  [  210/  258]\n",
      "Test Error: Avg loss: 105677.162760 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 27993854.000000  [   10/  258]\n",
      "loss: 20875702.000000  [  110/  258]\n",
      "loss: 17701054.000000  [  210/  258]\n",
      "Test Error: Avg loss: 58028.018663 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 25544552.000000  [   10/  258]\n",
      "loss: 22688640.000000  [  110/  258]\n",
      "loss: 27699858.000000  [  210/  258]\n",
      "Test Error: Avg loss: 21276.506944 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 39547260.000000  [   10/  258]\n",
      "loss: 60519208.000000  [  110/  258]\n",
      "loss: 10019438.000000  [  210/  258]\n",
      "Test Error: Avg loss: 13190.941189 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 17805052.000000  [   10/  258]\n",
      "loss: 27139332.000000  [  110/  258]\n",
      "loss: 17948558.000000  [  210/  258]\n",
      "Test Error: Avg loss: 15170.368001 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 21373920.000000  [   10/  258]\n",
      "loss: 31079532.000000  [  110/  258]\n",
      "loss: 7790451.500000  [  210/  258]\n",
      "Test Error: Avg loss: 18844.490668 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 23191552.000000  [   10/  258]\n",
      "loss: 24634258.000000  [  110/  258]\n",
      "loss: 15905268.000000  [  210/  258]\n",
      "Test Error: Avg loss: 31971.141059 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 23485626.000000  [   10/  258]\n",
      "loss: 44342712.000000  [  110/  258]\n",
      "loss: 19821924.000000  [  210/  258]\n",
      "Test Error: Avg loss: 27833.235460 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 16539645.000000  [   10/  258]\n",
      "loss: 16125203.000000  [  110/  258]\n",
      "loss: 17325866.000000  [  210/  258]\n",
      "Test Error: Avg loss: 23961.914062 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 16380067.000000  [   10/  258]\n",
      "loss: 18165734.000000  [  110/  258]\n",
      "loss: 22894964.000000  [  210/  258]\n",
      "Test Error: Avg loss: 16634.371419 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 15339616.000000  [   10/  258]\n",
      "loss: 8091711.000000  [  110/  258]\n",
      "loss: 7098648.000000  [  210/  258]\n",
      "Test Error: Avg loss: 28239.719835 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 16924896.000000  [   10/  258]\n",
      "loss: 22993822.000000  [  110/  258]\n",
      "loss: 8229994.500000  [  210/  258]\n",
      "Test Error: Avg loss: 25856.222548 \n",
      "\n",
      "Test Error: Avg loss: 25856.222548 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 184962048.000000  [   10/  258]\n",
      "loss: 154605344.000000  [  110/  258]\n",
      "loss: 164051904.000000  [  210/  258]\n",
      "Test Error: Avg loss: 851841.310764 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 202021728.000000  [   10/  258]\n",
      "loss: 117791504.000000  [  110/  258]\n",
      "loss: 153811136.000000  [  210/  258]\n",
      "Test Error: Avg loss: 630764.385417 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 195693696.000000  [   10/  258]\n",
      "loss: 145942688.000000  [  110/  258]\n",
      "loss: 95677760.000000  [  210/  258]\n",
      "Test Error: Avg loss: 374075.013889 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 95215328.000000  [   10/  258]\n",
      "loss: 92985416.000000  [  110/  258]\n",
      "loss: 75897448.000000  [  210/  258]\n",
      "Test Error: Avg loss: 306786.303819 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 66611500.000000  [   10/  258]\n",
      "loss: 96964000.000000  [  110/  258]\n",
      "loss: 44430200.000000  [  210/  258]\n",
      "Test Error: Avg loss: 325648.805556 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 50425156.000000  [   10/  258]\n",
      "loss: 70023792.000000  [  110/  258]\n",
      "loss: 99174960.000000  [  210/  258]\n",
      "Test Error: Avg loss: 294056.640625 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 169765472.000000  [   10/  258]\n",
      "loss: 91449104.000000  [  110/  258]\n",
      "loss: 25197108.000000  [  210/  258]\n",
      "Test Error: Avg loss: 299543.314236 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 56305064.000000  [   10/  258]\n",
      "loss: 34732688.000000  [  110/  258]\n",
      "loss: 41964984.000000  [  210/  258]\n",
      "Test Error: Avg loss: 252577.296875 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 57842648.000000  [   10/  258]\n",
      "loss: 52867356.000000  [  110/  258]\n",
      "loss: 38247344.000000  [  210/  258]\n",
      "Test Error: Avg loss: 215209.844618 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 89059304.000000  [   10/  258]\n",
      "loss: 40681424.000000  [  110/  258]\n",
      "loss: 17072020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 196698.894531 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 68810248.000000  [   10/  258]\n",
      "loss: 54642252.000000  [  110/  258]\n",
      "loss: 44140912.000000  [  210/  258]\n",
      "Test Error: Avg loss: 184094.320312 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 85489920.000000  [   10/  258]\n",
      "loss: 55871168.000000  [  110/  258]\n",
      "loss: 37005432.000000  [  210/  258]\n",
      "Test Error: Avg loss: 197178.132812 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 53133488.000000  [   10/  258]\n",
      "loss: 45390316.000000  [  110/  258]\n",
      "loss: 21878980.000000  [  210/  258]\n",
      "Test Error: Avg loss: 156520.574653 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 39545780.000000  [   10/  258]\n",
      "loss: 63776472.000000  [  110/  258]\n",
      "loss: 14558522.000000  [  210/  258]\n",
      "Test Error: Avg loss: 118599.437500 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 45505432.000000  [   10/  258]\n",
      "loss: 33783204.000000  [  110/  258]\n",
      "loss: 60023640.000000  [  210/  258]\n",
      "Test Error: Avg loss: 87760.428385 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 22459140.000000  [   10/  258]\n",
      "loss: 42542632.000000  [  110/  258]\n",
      "loss: 18854500.000000  [  210/  258]\n",
      "Test Error: Avg loss: 107151.407769 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 38276160.000000  [   10/  258]\n",
      "loss: 25088388.000000  [  110/  258]\n",
      "loss: 21264106.000000  [  210/  258]\n",
      "Test Error: Avg loss: 114954.686849 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 23532926.000000  [   10/  258]\n",
      "loss: 34869668.000000  [  110/  258]\n",
      "loss: 7187652.500000  [  210/  258]\n",
      "Test Error: Avg loss: 127274.726562 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 32737402.000000  [   10/  258]\n",
      "loss: 38366592.000000  [  110/  258]\n",
      "loss: 28575392.000000  [  210/  258]\n",
      "Test Error: Avg loss: 128180.386719 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 11811964.000000  [   10/  258]\n",
      "loss: 30710378.000000  [  110/  258]\n",
      "loss: 19068656.000000  [  210/  258]\n",
      "Test Error: Avg loss: 139148.628472 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 19459972.000000  [   10/  258]\n",
      "loss: 20817920.000000  [  110/  258]\n",
      "loss: 17045472.000000  [  210/  258]\n",
      "Test Error: Avg loss: 137889.141493 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 25508204.000000  [   10/  258]\n",
      "loss: 23715014.000000  [  110/  258]\n",
      "loss: 13896462.000000  [  210/  258]\n",
      "Test Error: Avg loss: 88925.381944 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 20314836.000000  [   10/  258]\n",
      "loss: 26901244.000000  [  110/  258]\n",
      "loss: 11382081.000000  [  210/  258]\n",
      "Test Error: Avg loss: 88991.124132 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 16980888.000000  [   10/  258]\n",
      "loss: 40928740.000000  [  110/  258]\n",
      "loss: 18806772.000000  [  210/  258]\n",
      "Test Error: Avg loss: 115917.414062 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 24839540.000000  [   10/  258]\n",
      "loss: 26380420.000000  [  110/  258]\n",
      "loss: 18514712.000000  [  210/  258]\n",
      "Test Error: Avg loss: 104605.458767 \n",
      "\n",
      "Test Error: Avg loss: 104605.458767 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 80921760.000000  [   10/  258]\n",
      "loss: 99237536.000000  [  110/  258]\n",
      "loss: 74096528.000000  [  210/  258]\n",
      "Test Error: Avg loss: 442317.069444 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 62680648.000000  [   10/  258]\n",
      "loss: 42926456.000000  [  110/  258]\n",
      "loss: 47686712.000000  [  210/  258]\n",
      "Test Error: Avg loss: 279348.209635 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 58176460.000000  [   10/  258]\n",
      "loss: 76576936.000000  [  110/  258]\n",
      "loss: 32152892.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181845.184028 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 44892072.000000  [   10/  258]\n",
      "loss: 36511932.000000  [  110/  258]\n",
      "loss: 16001320.000000  [  210/  258]\n",
      "Test Error: Avg loss: 220700.867188 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 62470768.000000  [   10/  258]\n",
      "loss: 63951840.000000  [  110/  258]\n",
      "loss: 60436736.000000  [  210/  258]\n",
      "Test Error: Avg loss: 205220.104167 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 28544750.000000  [   10/  258]\n",
      "loss: 25732044.000000  [  110/  258]\n",
      "loss: 19987084.000000  [  210/  258]\n",
      "Test Error: Avg loss: 206342.855035 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 19273452.000000  [   10/  258]\n",
      "loss: 27073588.000000  [  110/  258]\n",
      "loss: 18562230.000000  [  210/  258]\n",
      "Test Error: Avg loss: 165467.346354 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 20099440.000000  [   10/  258]\n",
      "loss: 57913832.000000  [  110/  258]\n",
      "loss: 18199762.000000  [  210/  258]\n",
      "Test Error: Avg loss: 172745.748264 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 39524080.000000  [   10/  258]\n",
      "loss: 88444848.000000  [  110/  258]\n",
      "loss: 36781060.000000  [  210/  258]\n",
      "Test Error: Avg loss: 176109.339410 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 39663732.000000  [   10/  258]\n",
      "loss: 18120724.000000  [  110/  258]\n",
      "loss: 19488800.000000  [  210/  258]\n",
      "Test Error: Avg loss: 162779.211806 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 17532478.000000  [   10/  258]\n",
      "loss: 29093524.000000  [  110/  258]\n",
      "loss: 15526390.000000  [  210/  258]\n",
      "Test Error: Avg loss: 164101.105903 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 20521644.000000  [   10/  258]\n",
      "loss: 54010756.000000  [  110/  258]\n",
      "loss: 23975752.000000  [  210/  258]\n",
      "Test Error: Avg loss: 166432.287326 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 12069712.000000  [   10/  258]\n",
      "loss: 35269124.000000  [  110/  258]\n",
      "loss: 16279498.000000  [  210/  258]\n",
      "Test Error: Avg loss: 169569.690104 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 18017924.000000  [   10/  258]\n",
      "loss: 22293576.000000  [  110/  258]\n",
      "loss: 14623901.000000  [  210/  258]\n",
      "Test Error: Avg loss: 107554.496528 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 17825608.000000  [   10/  258]\n",
      "loss: 20485900.000000  [  110/  258]\n",
      "loss: 7509924.000000  [  210/  258]\n",
      "Test Error: Avg loss: 119377.613281 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 29720328.000000  [   10/  258]\n",
      "loss: 24520104.000000  [  110/  258]\n",
      "loss: 12928244.000000  [  210/  258]\n",
      "Test Error: Avg loss: 113251.962240 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 10964050.000000  [   10/  258]\n",
      "loss: 21965822.000000  [  110/  258]\n",
      "loss: 13783477.000000  [  210/  258]\n",
      "Test Error: Avg loss: 78580.122396 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 13684389.000000  [   10/  258]\n",
      "loss: 22513152.000000  [  110/  258]\n",
      "loss: 5838019.000000  [  210/  258]\n",
      "Test Error: Avg loss: 74196.085069 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 6236628.000000  [   10/  258]\n",
      "loss: 7339731.500000  [  110/  258]\n",
      "loss: 13335184.000000  [  210/  258]\n",
      "Test Error: Avg loss: 63213.841146 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 23530222.000000  [   10/  258]\n",
      "loss: 13144411.000000  [  110/  258]\n",
      "loss: 7429780.000000  [  210/  258]\n",
      "Test Error: Avg loss: 62268.450955 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 12851673.000000  [   10/  258]\n",
      "loss: 18626476.000000  [  110/  258]\n",
      "loss: 6415081.000000  [  210/  258]\n",
      "Test Error: Avg loss: 30983.355903 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 19480554.000000  [   10/  258]\n",
      "loss: 6605262.500000  [  110/  258]\n",
      "loss: 8096363.000000  [  210/  258]\n",
      "Test Error: Avg loss: 41533.829427 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 13307074.000000  [   10/  258]\n",
      "loss: 11413999.000000  [  110/  258]\n",
      "loss: 11020982.000000  [  210/  258]\n",
      "Test Error: Avg loss: 64595.426649 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 6731845.000000  [   10/  258]\n",
      "loss: 11532874.000000  [  110/  258]\n",
      "loss: 27346134.000000  [  210/  258]\n",
      "Test Error: Avg loss: 45789.039280 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 15394383.000000  [   10/  258]\n",
      "loss: 7552955.500000  [  110/  258]\n",
      "loss: 7457199.000000  [  210/  258]\n",
      "Test Error: Avg loss: 30075.554253 \n",
      "\n",
      "Test Error: Avg loss: 30075.554253 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 176593408.000000  [   10/  258]\n",
      "loss: 370696576.000000  [  110/  258]\n",
      "loss: 138793232.000000  [  210/  258]\n",
      "Test Error: Avg loss: 976528.156250 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 230702640.000000  [   10/  258]\n",
      "loss: 98919096.000000  [  110/  258]\n",
      "loss: 84752960.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1321248.895833 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 92707408.000000  [   10/  258]\n",
      "loss: 139768656.000000  [  110/  258]\n",
      "loss: 52169952.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1292154.572917 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 52668440.000000  [   10/  258]\n",
      "loss: 106195744.000000  [  110/  258]\n",
      "loss: 46609804.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1244055.649306 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 58837648.000000  [   10/  258]\n",
      "loss: 109253456.000000  [  110/  258]\n",
      "loss: 53001988.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1063370.777778 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 89392320.000000  [   10/  258]\n",
      "loss: 156603104.000000  [  110/  258]\n",
      "loss: 59837892.000000  [  210/  258]\n",
      "Test Error: Avg loss: 868425.659722 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 92610480.000000  [   10/  258]\n",
      "loss: 77629136.000000  [  110/  258]\n",
      "loss: 48655836.000000  [  210/  258]\n",
      "Test Error: Avg loss: 745085.256944 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 62382744.000000  [   10/  258]\n",
      "loss: 70410304.000000  [  110/  258]\n",
      "loss: 24218968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 648868.930556 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 45974696.000000  [   10/  258]\n",
      "loss: 53599820.000000  [  110/  258]\n",
      "loss: 45280096.000000  [  210/  258]\n",
      "Test Error: Avg loss: 565187.454861 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 44361676.000000  [   10/  258]\n",
      "loss: 70255752.000000  [  110/  258]\n",
      "loss: 27949108.000000  [  210/  258]\n",
      "Test Error: Avg loss: 556683.039931 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 63886704.000000  [   10/  258]\n",
      "loss: 37078668.000000  [  110/  258]\n",
      "loss: 39128500.000000  [  210/  258]\n",
      "Test Error: Avg loss: 525163.347222 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 56323004.000000  [   10/  258]\n",
      "loss: 51499392.000000  [  110/  258]\n",
      "loss: 18527746.000000  [  210/  258]\n",
      "Test Error: Avg loss: 402577.590278 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 91766376.000000  [   10/  258]\n",
      "loss: 80539592.000000  [  110/  258]\n",
      "loss: 53714444.000000  [  210/  258]\n",
      "Test Error: Avg loss: 282503.136285 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 69254464.000000  [   10/  258]\n",
      "loss: 88020432.000000  [  110/  258]\n",
      "loss: 57067024.000000  [  210/  258]\n",
      "Test Error: Avg loss: 241391.913194 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 49713564.000000  [   10/  258]\n",
      "loss: 27735904.000000  [  110/  258]\n",
      "loss: 24146188.000000  [  210/  258]\n",
      "Test Error: Avg loss: 228730.807292 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 37705524.000000  [   10/  258]\n",
      "loss: 18768618.000000  [  110/  258]\n",
      "loss: 16467508.000000  [  210/  258]\n",
      "Test Error: Avg loss: 212585.997396 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 30272196.000000  [   10/  258]\n",
      "loss: 42244160.000000  [  110/  258]\n",
      "loss: 33304236.000000  [  210/  258]\n",
      "Test Error: Avg loss: 176537.486545 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 24820830.000000  [   10/  258]\n",
      "loss: 38436720.000000  [  110/  258]\n",
      "loss: 10148006.000000  [  210/  258]\n",
      "Test Error: Avg loss: 203414.248264 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 23078188.000000  [   10/  258]\n",
      "loss: 28742344.000000  [  110/  258]\n",
      "loss: 29085684.000000  [  210/  258]\n",
      "Test Error: Avg loss: 201737.213108 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 10257372.000000  [   10/  258]\n",
      "loss: 18267872.000000  [  110/  258]\n",
      "loss: 13818300.000000  [  210/  258]\n",
      "Test Error: Avg loss: 187808.287326 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 20837646.000000  [   10/  258]\n",
      "loss: 33773116.000000  [  110/  258]\n",
      "loss: 11700478.000000  [  210/  258]\n",
      "Test Error: Avg loss: 166776.308160 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 30989872.000000  [   10/  258]\n",
      "loss: 10330849.000000  [  110/  258]\n",
      "loss: 10126236.000000  [  210/  258]\n",
      "Test Error: Avg loss: 144042.315972 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 11094134.000000  [   10/  258]\n",
      "loss: 23134722.000000  [  110/  258]\n",
      "loss: 12467790.000000  [  210/  258]\n",
      "Test Error: Avg loss: 146396.540799 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 16202211.000000  [   10/  258]\n",
      "loss: 18487508.000000  [  110/  258]\n",
      "loss: 12418880.000000  [  210/  258]\n",
      "Test Error: Avg loss: 141159.858507 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 18055612.000000  [   10/  258]\n",
      "loss: 17191902.000000  [  110/  258]\n",
      "loss: 9074180.000000  [  210/  258]\n",
      "Test Error: Avg loss: 129208.200955 \n",
      "\n",
      "Test Error: Avg loss: 129208.200955 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 350273088.000000  [   10/  258]\n",
      "loss: 379021184.000000  [  110/  258]\n",
      "loss: 152660288.000000  [  210/  258]\n",
      "Test Error: Avg loss: 4352140.062500 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 180010624.000000  [   10/  258]\n",
      "loss: 164818800.000000  [  110/  258]\n",
      "loss: 184129248.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1726436.000000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 91267104.000000  [   10/  258]\n",
      "loss: 164745328.000000  [  110/  258]\n",
      "loss: 101762368.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1087639.159722 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 130405472.000000  [   10/  258]\n",
      "loss: 108077712.000000  [  110/  258]\n",
      "loss: 54817892.000000  [  210/  258]\n",
      "Test Error: Avg loss: 883125.298611 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 76017200.000000  [   10/  258]\n",
      "loss: 87604656.000000  [  110/  258]\n",
      "loss: 83447880.000000  [  210/  258]\n",
      "Test Error: Avg loss: 712970.059028 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 93044384.000000  [   10/  258]\n",
      "loss: 131314992.000000  [  110/  258]\n",
      "loss: 91972232.000000  [  210/  258]\n",
      "Test Error: Avg loss: 526250.930556 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 82590240.000000  [   10/  258]\n",
      "loss: 191939568.000000  [  110/  258]\n",
      "loss: 86721296.000000  [  210/  258]\n",
      "Test Error: Avg loss: 598927.763889 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 59881512.000000  [   10/  258]\n",
      "loss: 87989600.000000  [  110/  258]\n",
      "loss: 46578440.000000  [  210/  258]\n",
      "Test Error: Avg loss: 648430.263889 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 66105708.000000  [   10/  258]\n",
      "loss: 128472768.000000  [  110/  258]\n",
      "loss: 58312208.000000  [  210/  258]\n",
      "Test Error: Avg loss: 631025.927083 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 110199128.000000  [   10/  258]\n",
      "loss: 33394858.000000  [  110/  258]\n",
      "loss: 27286170.000000  [  210/  258]\n",
      "Test Error: Avg loss: 549624.763889 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 47012576.000000  [   10/  258]\n",
      "loss: 58966464.000000  [  110/  258]\n",
      "loss: 37190168.000000  [  210/  258]\n",
      "Test Error: Avg loss: 473250.850694 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 45298092.000000  [   10/  258]\n",
      "loss: 57550244.000000  [  110/  258]\n",
      "loss: 27580226.000000  [  210/  258]\n",
      "Test Error: Avg loss: 459737.295139 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 33966348.000000  [   10/  258]\n",
      "loss: 55677672.000000  [  110/  258]\n",
      "loss: 38530964.000000  [  210/  258]\n",
      "Test Error: Avg loss: 450332.762153 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 36131400.000000  [   10/  258]\n",
      "loss: 76227696.000000  [  110/  258]\n",
      "loss: 24499652.000000  [  210/  258]\n",
      "Test Error: Avg loss: 369650.820312 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 34225048.000000  [   10/  258]\n",
      "loss: 43673020.000000  [  110/  258]\n",
      "loss: 33274038.000000  [  210/  258]\n",
      "Test Error: Avg loss: 283508.847222 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 32332678.000000  [   10/  258]\n",
      "loss: 44500376.000000  [  110/  258]\n",
      "loss: 30947776.000000  [  210/  258]\n",
      "Test Error: Avg loss: 264902.462674 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 23496922.000000  [   10/  258]\n",
      "loss: 43376980.000000  [  110/  258]\n",
      "loss: 22857490.000000  [  210/  258]\n",
      "Test Error: Avg loss: 270482.526042 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 19425604.000000  [   10/  258]\n",
      "loss: 21302652.000000  [  110/  258]\n",
      "loss: 16176347.000000  [  210/  258]\n",
      "Test Error: Avg loss: 228757.500868 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 36119688.000000  [   10/  258]\n",
      "loss: 39167616.000000  [  110/  258]\n",
      "loss: 45419200.000000  [  210/  258]\n",
      "Test Error: Avg loss: 185932.980035 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 24778288.000000  [   10/  258]\n",
      "loss: 30410024.000000  [  110/  258]\n",
      "loss: 24245764.000000  [  210/  258]\n",
      "Test Error: Avg loss: 191445.793403 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 16658546.000000  [   10/  258]\n",
      "loss: 22675992.000000  [  110/  258]\n",
      "loss: 21896988.000000  [  210/  258]\n",
      "Test Error: Avg loss: 226932.915799 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 26581716.000000  [   10/  258]\n",
      "loss: 27362624.000000  [  110/  258]\n",
      "loss: 14359851.000000  [  210/  258]\n",
      "Test Error: Avg loss: 213382.324653 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 31426224.000000  [   10/  258]\n",
      "loss: 42520620.000000  [  110/  258]\n",
      "loss: 29618100.000000  [  210/  258]\n",
      "Test Error: Avg loss: 168461.657118 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 19986128.000000  [   10/  258]\n",
      "loss: 18953356.000000  [  110/  258]\n",
      "loss: 30184186.000000  [  210/  258]\n",
      "Test Error: Avg loss: 143689.914062 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 11881560.000000  [   10/  258]\n",
      "loss: 20890494.000000  [  110/  258]\n",
      "loss: 48570036.000000  [  210/  258]\n",
      "Test Error: Avg loss: 121235.195312 \n",
      "\n",
      "Test Error: Avg loss: 121235.195312 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 904626944.000000  [   10/  258]\n",
      "loss: 510670176.000000  [  110/  258]\n",
      "loss: 304171328.000000  [  210/  258]\n",
      "Test Error: Avg loss: 704037.694444 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 233119360.000000  [   10/  258]\n",
      "loss: 187899008.000000  [  110/  258]\n",
      "loss: 228292208.000000  [  210/  258]\n",
      "Test Error: Avg loss: 901467.041667 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 173663040.000000  [   10/  258]\n",
      "loss: 153013856.000000  [  110/  258]\n",
      "loss: 140501392.000000  [  210/  258]\n",
      "Test Error: Avg loss: 568139.482639 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 163746688.000000  [   10/  258]\n",
      "loss: 192439744.000000  [  110/  258]\n",
      "loss: 147821968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 220964.135417 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 98637536.000000  [   10/  258]\n",
      "loss: 143707728.000000  [  110/  258]\n",
      "loss: 57437920.000000  [  210/  258]\n",
      "Test Error: Avg loss: 169793.383681 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 125077616.000000  [   10/  258]\n",
      "loss: 109339760.000000  [  110/  258]\n",
      "loss: 48173768.000000  [  210/  258]\n",
      "Test Error: Avg loss: 250239.268229 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 83344288.000000  [   10/  258]\n",
      "loss: 106940664.000000  [  110/  258]\n",
      "loss: 168214624.000000  [  210/  258]\n",
      "Test Error: Avg loss: 225678.097222 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 91292240.000000  [   10/  258]\n",
      "loss: 83519936.000000  [  110/  258]\n",
      "loss: 102028464.000000  [  210/  258]\n",
      "Test Error: Avg loss: 200825.664062 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 81980432.000000  [   10/  258]\n",
      "loss: 132367608.000000  [  110/  258]\n",
      "loss: 84110864.000000  [  210/  258]\n",
      "Test Error: Avg loss: 208354.435764 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 68451520.000000  [   10/  258]\n",
      "loss: 46477576.000000  [  110/  258]\n",
      "loss: 33204604.000000  [  210/  258]\n",
      "Test Error: Avg loss: 183556.941406 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 37475504.000000  [   10/  258]\n",
      "loss: 63864032.000000  [  110/  258]\n",
      "loss: 88378192.000000  [  210/  258]\n",
      "Test Error: Avg loss: 185434.176215 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 62557140.000000  [   10/  258]\n",
      "loss: 66327492.000000  [  110/  258]\n",
      "loss: 68009808.000000  [  210/  258]\n",
      "Test Error: Avg loss: 193668.460938 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 34135464.000000  [   10/  258]\n",
      "loss: 69622664.000000  [  110/  258]\n",
      "loss: 25950174.000000  [  210/  258]\n",
      "Test Error: Avg loss: 202292.344618 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 65380380.000000  [   10/  258]\n",
      "loss: 55571112.000000  [  110/  258]\n",
      "loss: 65974456.000000  [  210/  258]\n",
      "Test Error: Avg loss: 206868.873264 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 42373432.000000  [   10/  258]\n",
      "loss: 46265264.000000  [  110/  258]\n",
      "loss: 20057420.000000  [  210/  258]\n",
      "Test Error: Avg loss: 211319.450521 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 46046472.000000  [   10/  258]\n",
      "loss: 49718404.000000  [  110/  258]\n",
      "loss: 30071248.000000  [  210/  258]\n",
      "Test Error: Avg loss: 205200.050347 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 34537460.000000  [   10/  258]\n",
      "loss: 41893136.000000  [  110/  258]\n",
      "loss: 29283732.000000  [  210/  258]\n",
      "Test Error: Avg loss: 196648.157118 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 52640960.000000  [   10/  258]\n",
      "loss: 35440216.000000  [  110/  258]\n",
      "loss: 44337144.000000  [  210/  258]\n",
      "Test Error: Avg loss: 191682.462674 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 33922724.000000  [   10/  258]\n",
      "loss: 38891672.000000  [  110/  258]\n",
      "loss: 12401485.000000  [  210/  258]\n",
      "Test Error: Avg loss: 186179.945312 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 39579816.000000  [   10/  258]\n",
      "loss: 83374984.000000  [  110/  258]\n",
      "loss: 37584336.000000  [  210/  258]\n",
      "Test Error: Avg loss: 189880.302083 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 35701624.000000  [   10/  258]\n",
      "loss: 34368012.000000  [  110/  258]\n",
      "loss: 25277020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 180043.275174 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 29612608.000000  [   10/  258]\n",
      "loss: 49432200.000000  [  110/  258]\n",
      "loss: 13078762.000000  [  210/  258]\n",
      "Test Error: Avg loss: 158435.861111 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 31461084.000000  [   10/  258]\n",
      "loss: 38487504.000000  [  110/  258]\n",
      "loss: 20730440.000000  [  210/  258]\n",
      "Test Error: Avg loss: 149179.147569 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 33286816.000000  [   10/  258]\n",
      "loss: 33546406.000000  [  110/  258]\n",
      "loss: 26013428.000000  [  210/  258]\n",
      "Test Error: Avg loss: 147560.705729 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 24330546.000000  [   10/  258]\n",
      "loss: 25686860.000000  [  110/  258]\n",
      "loss: 25057524.000000  [  210/  258]\n",
      "Test Error: Avg loss: 125321.675347 \n",
      "\n",
      "Test Error: Avg loss: 125321.675347 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 395997184.000000  [   10/  258]\n",
      "loss: 393524992.000000  [  110/  258]\n",
      "loss: 414163136.000000  [  210/  258]\n",
      "Test Error: Avg loss: 9574910.777778 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 403701344.000000  [   10/  258]\n",
      "loss: 353935104.000000  [  110/  258]\n",
      "loss: 257664544.000000  [  210/  258]\n",
      "Test Error: Avg loss: 4894371.055556 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 139293488.000000  [   10/  258]\n",
      "loss: 175435520.000000  [  110/  258]\n",
      "loss: 261944608.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2642922.083333 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 231470592.000000  [   10/  258]\n",
      "loss: 241684960.000000  [  110/  258]\n",
      "loss: 155092288.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1350501.000000 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 153994672.000000  [   10/  258]\n",
      "loss: 114176080.000000  [  110/  258]\n",
      "loss: 322553632.000000  [  210/  258]\n",
      "Test Error: Avg loss: 622647.552083 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 102925632.000000  [   10/  258]\n",
      "loss: 69624992.000000  [  110/  258]\n",
      "loss: 128380064.000000  [  210/  258]\n",
      "Test Error: Avg loss: 575916.413194 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 77780720.000000  [   10/  258]\n",
      "loss: 54558660.000000  [  110/  258]\n",
      "loss: 87733744.000000  [  210/  258]\n",
      "Test Error: Avg loss: 461994.055556 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 73959712.000000  [   10/  258]\n",
      "loss: 101390368.000000  [  110/  258]\n",
      "loss: 67787768.000000  [  210/  258]\n",
      "Test Error: Avg loss: 474190.423611 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 119892704.000000  [   10/  258]\n",
      "loss: 145604768.000000  [  110/  258]\n",
      "loss: 48340632.000000  [  210/  258]\n",
      "Test Error: Avg loss: 426263.038194 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 83739592.000000  [   10/  258]\n",
      "loss: 54308792.000000  [  110/  258]\n",
      "loss: 73113240.000000  [  210/  258]\n",
      "Test Error: Avg loss: 320993.774306 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 75459040.000000  [   10/  258]\n",
      "loss: 35190692.000000  [  110/  258]\n",
      "loss: 63873020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 248972.461806 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 67509992.000000  [   10/  258]\n",
      "loss: 37676544.000000  [  110/  258]\n",
      "loss: 72442216.000000  [  210/  258]\n",
      "Test Error: Avg loss: 157653.935764 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 66512376.000000  [   10/  258]\n",
      "loss: 50773664.000000  [  110/  258]\n",
      "loss: 35734704.000000  [  210/  258]\n",
      "Test Error: Avg loss: 208831.608507 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 46536760.000000  [   10/  258]\n",
      "loss: 46205320.000000  [  110/  258]\n",
      "loss: 56095488.000000  [  210/  258]\n",
      "Test Error: Avg loss: 120308.009983 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 68115616.000000  [   10/  258]\n",
      "loss: 54898660.000000  [  110/  258]\n",
      "loss: 52207124.000000  [  210/  258]\n",
      "Test Error: Avg loss: 122283.040799 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 37618576.000000  [   10/  258]\n",
      "loss: 47909744.000000  [  110/  258]\n",
      "loss: 22718198.000000  [  210/  258]\n",
      "Test Error: Avg loss: 108729.156684 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 30762046.000000  [   10/  258]\n",
      "loss: 21540642.000000  [  110/  258]\n",
      "loss: 38659100.000000  [  210/  258]\n",
      "Test Error: Avg loss: 78518.032986 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 36550892.000000  [   10/  258]\n",
      "loss: 37760932.000000  [  110/  258]\n",
      "loss: 38173408.000000  [  210/  258]\n",
      "Test Error: Avg loss: 92892.842882 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 23383728.000000  [   10/  258]\n",
      "loss: 43490784.000000  [  110/  258]\n",
      "loss: 29407700.000000  [  210/  258]\n",
      "Test Error: Avg loss: 103582.154080 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 13008458.000000  [   10/  258]\n",
      "loss: 20669024.000000  [  110/  258]\n",
      "loss: 34848136.000000  [  210/  258]\n",
      "Test Error: Avg loss: 108996.319878 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 27568412.000000  [   10/  258]\n",
      "loss: 14584638.000000  [  110/  258]\n",
      "loss: 67245304.000000  [  210/  258]\n",
      "Test Error: Avg loss: 90410.409288 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 55636728.000000  [   10/  258]\n",
      "loss: 21332002.000000  [  110/  258]\n",
      "loss: 26261326.000000  [  210/  258]\n",
      "Test Error: Avg loss: 59110.906901 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 20100950.000000  [   10/  258]\n",
      "loss: 33913152.000000  [  110/  258]\n",
      "loss: 25998340.000000  [  210/  258]\n",
      "Test Error: Avg loss: 47648.557617 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 20194980.000000  [   10/  258]\n",
      "loss: 15826877.000000  [  110/  258]\n",
      "loss: 39119076.000000  [  210/  258]\n",
      "Test Error: Avg loss: 40966.939453 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 27881544.000000  [   10/  258]\n",
      "loss: 31088308.000000  [  110/  258]\n",
      "loss: 20652400.000000  [  210/  258]\n",
      "Test Error: Avg loss: 60496.667101 \n",
      "\n",
      "Test Error: Avg loss: 60496.667101 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 242477120.000000  [   10/  258]\n",
      "loss: 353042656.000000  [  110/  258]\n",
      "loss: 63028424.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1110778.395833 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 177633328.000000  [   10/  258]\n",
      "loss: 191400416.000000  [  110/  258]\n",
      "loss: 56757304.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1370342.333333 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 123730464.000000  [   10/  258]\n",
      "loss: 220125168.000000  [  110/  258]\n",
      "loss: 73569936.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1211707.680556 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 103601288.000000  [   10/  258]\n",
      "loss: 209369824.000000  [  110/  258]\n",
      "loss: 38625744.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1014991.451389 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 105654960.000000  [   10/  258]\n",
      "loss: 124768416.000000  [  110/  258]\n",
      "loss: 57687932.000000  [  210/  258]\n",
      "Test Error: Avg loss: 866599.527778 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 76803808.000000  [   10/  258]\n",
      "loss: 64583504.000000  [  110/  258]\n",
      "loss: 36361992.000000  [  210/  258]\n",
      "Test Error: Avg loss: 718171.194444 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 104751888.000000  [   10/  258]\n",
      "loss: 94902424.000000  [  110/  258]\n",
      "loss: 41116596.000000  [  210/  258]\n",
      "Test Error: Avg loss: 520625.531250 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 92357592.000000  [   10/  258]\n",
      "loss: 140459232.000000  [  110/  258]\n",
      "loss: 20382852.000000  [  210/  258]\n",
      "Test Error: Avg loss: 461902.402778 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 39595864.000000  [   10/  258]\n",
      "loss: 130623000.000000  [  110/  258]\n",
      "loss: 50896532.000000  [  210/  258]\n",
      "Test Error: Avg loss: 451725.357639 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 54959280.000000  [   10/  258]\n",
      "loss: 68613920.000000  [  110/  258]\n",
      "loss: 30525264.000000  [  210/  258]\n",
      "Test Error: Avg loss: 302868.633681 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 40040800.000000  [   10/  258]\n",
      "loss: 41784624.000000  [  110/  258]\n",
      "loss: 18107416.000000  [  210/  258]\n",
      "Test Error: Avg loss: 223407.928819 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 102644216.000000  [   10/  258]\n",
      "loss: 50349036.000000  [  110/  258]\n",
      "loss: 20560474.000000  [  210/  258]\n",
      "Test Error: Avg loss: 209272.010417 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 42391352.000000  [   10/  258]\n",
      "loss: 57591592.000000  [  110/  258]\n",
      "loss: 19409780.000000  [  210/  258]\n",
      "Test Error: Avg loss: 169395.175347 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 49336304.000000  [   10/  258]\n",
      "loss: 54895392.000000  [  110/  258]\n",
      "loss: 31350728.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181492.817708 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 34077448.000000  [   10/  258]\n",
      "loss: 39326680.000000  [  110/  258]\n",
      "loss: 28025370.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181086.141493 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 46909308.000000  [   10/  258]\n",
      "loss: 35158592.000000  [  110/  258]\n",
      "loss: 12897076.000000  [  210/  258]\n",
      "Test Error: Avg loss: 162291.267361 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 45819064.000000  [   10/  258]\n",
      "loss: 59562720.000000  [  110/  258]\n",
      "loss: 11750778.000000  [  210/  258]\n",
      "Test Error: Avg loss: 160637.767361 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 43608276.000000  [   10/  258]\n",
      "loss: 58658488.000000  [  110/  258]\n",
      "loss: 13539616.000000  [  210/  258]\n",
      "Test Error: Avg loss: 136755.092014 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 14259377.000000  [   10/  258]\n",
      "loss: 31640236.000000  [  110/  258]\n",
      "loss: 17404822.000000  [  210/  258]\n",
      "Test Error: Avg loss: 165472.496528 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 26471656.000000  [   10/  258]\n",
      "loss: 29542542.000000  [  110/  258]\n",
      "loss: 8617557.000000  [  210/  258]\n",
      "Test Error: Avg loss: 163429.967882 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 15418812.000000  [   10/  258]\n",
      "loss: 23862934.000000  [  110/  258]\n",
      "loss: 6305898.000000  [  210/  258]\n",
      "Test Error: Avg loss: 141504.545139 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 20004690.000000  [   10/  258]\n",
      "loss: 15034036.000000  [  110/  258]\n",
      "loss: 7662404.500000  [  210/  258]\n",
      "Test Error: Avg loss: 122062.176215 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 21710196.000000  [   10/  258]\n",
      "loss: 22774558.000000  [  110/  258]\n",
      "loss: 12942508.000000  [  210/  258]\n",
      "Test Error: Avg loss: 110642.335938 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 14518921.000000  [   10/  258]\n",
      "loss: 31107484.000000  [  110/  258]\n",
      "loss: 17187372.000000  [  210/  258]\n",
      "Test Error: Avg loss: 102909.262153 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 18259582.000000  [   10/  258]\n",
      "loss: 33076404.000000  [  110/  258]\n",
      "loss: 11362255.000000  [  210/  258]\n",
      "Test Error: Avg loss: 97172.328993 \n",
      "\n",
      "Test Error: Avg loss: 97172.328993 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1150604800.000000  [   10/  258]\n",
      "loss: 585614976.000000  [  110/  258]\n",
      "loss: 1104930048.000000  [  210/  258]\n",
      "Test Error: Avg loss: 12786255.166667 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 550419008.000000  [   10/  258]\n",
      "loss: 399619904.000000  [  110/  258]\n",
      "loss: 234668000.000000  [  210/  258]\n",
      "Test Error: Avg loss: 5380559.666667 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 242209472.000000  [   10/  258]\n",
      "loss: 217342464.000000  [  110/  258]\n",
      "loss: 300679328.000000  [  210/  258]\n",
      "Test Error: Avg loss: 3354887.541667 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 158767872.000000  [   10/  258]\n",
      "loss: 131984944.000000  [  110/  258]\n",
      "loss: 438960992.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2056410.888889 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 222067616.000000  [   10/  258]\n",
      "loss: 242394880.000000  [  110/  258]\n",
      "loss: 177440496.000000  [  210/  258]\n",
      "Test Error: Avg loss: 930399.284722 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 141096976.000000  [   10/  258]\n",
      "loss: 154756960.000000  [  110/  258]\n",
      "loss: 160745040.000000  [  210/  258]\n",
      "Test Error: Avg loss: 682292.937500 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 175500832.000000  [   10/  258]\n",
      "loss: 94039264.000000  [  110/  258]\n",
      "loss: 142024560.000000  [  210/  258]\n",
      "Test Error: Avg loss: 394222.593750 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 152193776.000000  [   10/  258]\n",
      "loss: 121576432.000000  [  110/  258]\n",
      "loss: 58684040.000000  [  210/  258]\n",
      "Test Error: Avg loss: 247070.753472 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 227464128.000000  [   10/  258]\n",
      "loss: 45626856.000000  [  110/  258]\n",
      "loss: 125601024.000000  [  210/  258]\n",
      "Test Error: Avg loss: 103770.772135 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 189483648.000000  [   10/  258]\n",
      "loss: 82711752.000000  [  110/  258]\n",
      "loss: 102903024.000000  [  210/  258]\n",
      "Test Error: Avg loss: 84403.138889 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 63549712.000000  [   10/  258]\n",
      "loss: 98325088.000000  [  110/  258]\n",
      "loss: 81176592.000000  [  210/  258]\n",
      "Test Error: Avg loss: 110606.864583 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 124232976.000000  [   10/  258]\n",
      "loss: 60664504.000000  [  110/  258]\n",
      "loss: 25590124.000000  [  210/  258]\n",
      "Test Error: Avg loss: 138047.886285 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 94431560.000000  [   10/  258]\n",
      "loss: 115026704.000000  [  110/  258]\n",
      "loss: 75927200.000000  [  210/  258]\n",
      "Test Error: Avg loss: 93948.653212 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 66074156.000000  [   10/  258]\n",
      "loss: 47928072.000000  [  110/  258]\n",
      "loss: 65682548.000000  [  210/  258]\n",
      "Test Error: Avg loss: 106635.276042 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 56675924.000000  [   10/  258]\n",
      "loss: 66932000.000000  [  110/  258]\n",
      "loss: 43786228.000000  [  210/  258]\n",
      "Test Error: Avg loss: 72625.611545 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 92013176.000000  [   10/  258]\n",
      "loss: 50251664.000000  [  110/  258]\n",
      "loss: 28268140.000000  [  210/  258]\n",
      "Test Error: Avg loss: 122362.201823 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 49089144.000000  [   10/  258]\n",
      "loss: 72586896.000000  [  110/  258]\n",
      "loss: 105999232.000000  [  210/  258]\n",
      "Test Error: Avg loss: 116250.029514 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 47587088.000000  [   10/  258]\n",
      "loss: 27545388.000000  [  110/  258]\n",
      "loss: 110183168.000000  [  210/  258]\n",
      "Test Error: Avg loss: 126114.943576 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 61705368.000000  [   10/  258]\n",
      "loss: 63647256.000000  [  110/  258]\n",
      "loss: 37458736.000000  [  210/  258]\n",
      "Test Error: Avg loss: 129033.275174 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 51026940.000000  [   10/  258]\n",
      "loss: 56652520.000000  [  110/  258]\n",
      "loss: 41991064.000000  [  210/  258]\n",
      "Test Error: Avg loss: 126946.809896 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 65390112.000000  [   10/  258]\n",
      "loss: 38535912.000000  [  110/  258]\n",
      "loss: 19701520.000000  [  210/  258]\n",
      "Test Error: Avg loss: 127580.779514 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 23098462.000000  [   10/  258]\n",
      "loss: 44695040.000000  [  110/  258]\n",
      "loss: 33672076.000000  [  210/  258]\n",
      "Test Error: Avg loss: 121168.793403 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 29077364.000000  [   10/  258]\n",
      "loss: 28499682.000000  [  110/  258]\n",
      "loss: 21430020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 94172.414931 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 30090232.000000  [   10/  258]\n",
      "loss: 38001816.000000  [  110/  258]\n",
      "loss: 32945782.000000  [  210/  258]\n",
      "Test Error: Avg loss: 71223.187500 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 14029342.000000  [   10/  258]\n",
      "loss: 31876828.000000  [  110/  258]\n",
      "loss: 14935622.000000  [  210/  258]\n",
      "Test Error: Avg loss: 85561.686632 \n",
      "\n",
      "Test Error: Avg loss: 85561.686632 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 132764136.000000  [   10/  258]\n",
      "loss: 150269184.000000  [  110/  258]\n",
      "loss: 51836992.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1618480.340278 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 60634572.000000  [   10/  258]\n",
      "loss: 115732144.000000  [  110/  258]\n",
      "loss: 20045576.000000  [  210/  258]\n",
      "Test Error: Avg loss: 894974.034722 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 55156768.000000  [   10/  258]\n",
      "loss: 32202658.000000  [  110/  258]\n",
      "loss: 59968112.000000  [  210/  258]\n",
      "Test Error: Avg loss: 548640.739583 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 26155596.000000  [   10/  258]\n",
      "loss: 101498328.000000  [  110/  258]\n",
      "loss: 52961728.000000  [  210/  258]\n",
      "Test Error: Avg loss: 398504.486111 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 25332026.000000  [   10/  258]\n",
      "loss: 44679440.000000  [  110/  258]\n",
      "loss: 65956788.000000  [  210/  258]\n",
      "Test Error: Avg loss: 435714.017361 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 39490528.000000  [   10/  258]\n",
      "loss: 62157056.000000  [  110/  258]\n",
      "loss: 32383262.000000  [  210/  258]\n",
      "Test Error: Avg loss: 330503.098958 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 33113232.000000  [   10/  258]\n",
      "loss: 40317520.000000  [  110/  258]\n",
      "loss: 42067056.000000  [  210/  258]\n",
      "Test Error: Avg loss: 259681.956597 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 17459018.000000  [   10/  258]\n",
      "loss: 45494896.000000  [  110/  258]\n",
      "loss: 32941692.000000  [  210/  258]\n",
      "Test Error: Avg loss: 176982.673611 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 40102236.000000  [   10/  258]\n",
      "loss: 30870552.000000  [  110/  258]\n",
      "loss: 23123594.000000  [  210/  258]\n",
      "Test Error: Avg loss: 132276.304688 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 29953702.000000  [   10/  258]\n",
      "loss: 29285588.000000  [  110/  258]\n",
      "loss: 16801816.000000  [  210/  258]\n",
      "Test Error: Avg loss: 106076.971788 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 12356240.000000  [   10/  258]\n",
      "loss: 29929912.000000  [  110/  258]\n",
      "loss: 10889448.000000  [  210/  258]\n",
      "Test Error: Avg loss: 113409.335069 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 20506876.000000  [   10/  258]\n",
      "loss: 34987960.000000  [  110/  258]\n",
      "loss: 18430630.000000  [  210/  258]\n",
      "Test Error: Avg loss: 121949.011285 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 25862520.000000  [   10/  258]\n",
      "loss: 16271441.000000  [  110/  258]\n",
      "loss: 15757968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 149537.277778 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 23942054.000000  [   10/  258]\n",
      "loss: 47497720.000000  [  110/  258]\n",
      "loss: 10025715.000000  [  210/  258]\n",
      "Test Error: Avg loss: 150049.046007 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 17298184.000000  [   10/  258]\n",
      "loss: 35092224.000000  [  110/  258]\n",
      "loss: 15432115.000000  [  210/  258]\n",
      "Test Error: Avg loss: 147620.191840 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 11752268.000000  [   10/  258]\n",
      "loss: 23690116.000000  [  110/  258]\n",
      "loss: 16345212.000000  [  210/  258]\n",
      "Test Error: Avg loss: 126652.097222 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 14659329.000000  [   10/  258]\n",
      "loss: 18363940.000000  [  110/  258]\n",
      "loss: 10062424.000000  [  210/  258]\n",
      "Test Error: Avg loss: 66995.468316 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 8402592.000000  [   10/  258]\n",
      "loss: 40342864.000000  [  110/  258]\n",
      "loss: 16856826.000000  [  210/  258]\n",
      "Test Error: Avg loss: 51357.361545 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 16181980.000000  [   10/  258]\n",
      "loss: 11688628.000000  [  110/  258]\n",
      "loss: 9552840.000000  [  210/  258]\n",
      "Test Error: Avg loss: 53995.302083 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 21128300.000000  [   10/  258]\n",
      "loss: 20426992.000000  [  110/  258]\n",
      "loss: 6090616.500000  [  210/  258]\n",
      "Test Error: Avg loss: 54875.684462 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 11576791.000000  [   10/  258]\n",
      "loss: 26206832.000000  [  110/  258]\n",
      "loss: 11846392.000000  [  210/  258]\n",
      "Test Error: Avg loss: 46516.367622 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 11794918.000000  [   10/  258]\n",
      "loss: 14496269.000000  [  110/  258]\n",
      "loss: 12026214.000000  [  210/  258]\n",
      "Test Error: Avg loss: 23721.402778 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 8779632.000000  [   10/  258]\n",
      "loss: 8031231.000000  [  110/  258]\n",
      "loss: 10225968.000000  [  210/  258]\n",
      "Test Error: Avg loss: 30893.221137 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 10022126.000000  [   10/  258]\n",
      "loss: 13440154.000000  [  110/  258]\n",
      "loss: 18069900.000000  [  210/  258]\n",
      "Test Error: Avg loss: 27669.580729 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 12751834.000000  [   10/  258]\n",
      "loss: 13043082.000000  [  110/  258]\n",
      "loss: 9907000.000000  [  210/  258]\n",
      "Test Error: Avg loss: 32065.967882 \n",
      "\n",
      "Test Error: Avg loss: 32065.967882 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 529655040.000000  [   10/  258]\n",
      "loss: 221085504.000000  [  110/  258]\n",
      "loss: 254119040.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1655586.847222 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 252964672.000000  [   10/  258]\n",
      "loss: 122715032.000000  [  110/  258]\n",
      "loss: 147391808.000000  [  210/  258]\n",
      "Test Error: Avg loss: 138569.887153 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 88542000.000000  [   10/  258]\n",
      "loss: 175325024.000000  [  110/  258]\n",
      "loss: 53474460.000000  [  210/  258]\n",
      "Test Error: Avg loss: 248298.543403 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 126450112.000000  [   10/  258]\n",
      "loss: 141556736.000000  [  110/  258]\n",
      "loss: 56096952.000000  [  210/  258]\n",
      "Test Error: Avg loss: 232820.730903 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 71587536.000000  [   10/  258]\n",
      "loss: 145185680.000000  [  110/  258]\n",
      "loss: 62996168.000000  [  210/  258]\n",
      "Test Error: Avg loss: 204855.226562 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 99235760.000000  [   10/  258]\n",
      "loss: 85507712.000000  [  110/  258]\n",
      "loss: 112568136.000000  [  210/  258]\n",
      "Test Error: Avg loss: 182415.862847 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 39517408.000000  [   10/  258]\n",
      "loss: 239188160.000000  [  110/  258]\n",
      "loss: 44447936.000000  [  210/  258]\n",
      "Test Error: Avg loss: 296790.913194 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 56630896.000000  [   10/  258]\n",
      "loss: 54496780.000000  [  110/  258]\n",
      "loss: 83601792.000000  [  210/  258]\n",
      "Test Error: Avg loss: 391466.888889 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 39100768.000000  [   10/  258]\n",
      "loss: 91479768.000000  [  110/  258]\n",
      "loss: 69964664.000000  [  210/  258]\n",
      "Test Error: Avg loss: 385159.993056 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 69450880.000000  [   10/  258]\n",
      "loss: 42138952.000000  [  110/  258]\n",
      "loss: 24448484.000000  [  210/  258]\n",
      "Test Error: Avg loss: 431607.538194 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 89247152.000000  [   10/  258]\n",
      "loss: 30444516.000000  [  110/  258]\n",
      "loss: 93339264.000000  [  210/  258]\n",
      "Test Error: Avg loss: 481413.350694 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 42426724.000000  [   10/  258]\n",
      "loss: 58795208.000000  [  110/  258]\n",
      "loss: 38574340.000000  [  210/  258]\n",
      "Test Error: Avg loss: 495883.704861 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 30868952.000000  [   10/  258]\n",
      "loss: 56935808.000000  [  110/  258]\n",
      "loss: 26510326.000000  [  210/  258]\n",
      "Test Error: Avg loss: 465139.364583 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 62921260.000000  [   10/  258]\n",
      "loss: 28991020.000000  [  110/  258]\n",
      "loss: 58869780.000000  [  210/  258]\n",
      "Test Error: Avg loss: 472759.329861 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 27663128.000000  [   10/  258]\n",
      "loss: 34622400.000000  [  110/  258]\n",
      "loss: 19136664.000000  [  210/  258]\n",
      "Test Error: Avg loss: 449568.604167 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 34257276.000000  [   10/  258]\n",
      "loss: 49504904.000000  [  110/  258]\n",
      "loss: 50961552.000000  [  210/  258]\n",
      "Test Error: Avg loss: 408318.347222 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 24360326.000000  [   10/  258]\n",
      "loss: 43886244.000000  [  110/  258]\n",
      "loss: 20929196.000000  [  210/  258]\n",
      "Test Error: Avg loss: 385002.208333 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 22463112.000000  [   10/  258]\n",
      "loss: 26459412.000000  [  110/  258]\n",
      "loss: 25807260.000000  [  210/  258]\n",
      "Test Error: Avg loss: 370906.218750 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 18265628.000000  [   10/  258]\n",
      "loss: 47507928.000000  [  110/  258]\n",
      "loss: 14465428.000000  [  210/  258]\n",
      "Test Error: Avg loss: 361026.034722 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 18722170.000000  [   10/  258]\n",
      "loss: 33604384.000000  [  110/  258]\n",
      "loss: 8931906.000000  [  210/  258]\n",
      "Test Error: Avg loss: 338075.888889 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 29033286.000000  [   10/  258]\n",
      "loss: 26047998.000000  [  110/  258]\n",
      "loss: 25446638.000000  [  210/  258]\n",
      "Test Error: Avg loss: 312820.163194 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 22246188.000000  [   10/  258]\n",
      "loss: 19681578.000000  [  110/  258]\n",
      "loss: 15760020.000000  [  210/  258]\n",
      "Test Error: Avg loss: 267455.786458 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 25766748.000000  [   10/  258]\n",
      "loss: 28588254.000000  [  110/  258]\n",
      "loss: 21440372.000000  [  210/  258]\n",
      "Test Error: Avg loss: 228132.555556 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 27187256.000000  [   10/  258]\n",
      "loss: 29341394.000000  [  110/  258]\n",
      "loss: 11501270.000000  [  210/  258]\n",
      "Test Error: Avg loss: 215402.960069 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 29154556.000000  [   10/  258]\n",
      "loss: 22755286.000000  [  110/  258]\n",
      "loss: 17086922.000000  [  210/  258]\n",
      "Test Error: Avg loss: 185278.786458 \n",
      "\n",
      "Test Error: Avg loss: 185278.786458 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 279121184.000000  [   10/  258]\n",
      "loss: 297270464.000000  [  110/  258]\n",
      "loss: 147727072.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1703361.472222 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 106404096.000000  [   10/  258]\n",
      "loss: 60265900.000000  [  110/  258]\n",
      "loss: 63378852.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1095803.215278 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 112131792.000000  [   10/  258]\n",
      "loss: 28618740.000000  [  110/  258]\n",
      "loss: 75655568.000000  [  210/  258]\n",
      "Test Error: Avg loss: 785712.534722 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 46650004.000000  [   10/  258]\n",
      "loss: 61856696.000000  [  110/  258]\n",
      "loss: 34568096.000000  [  210/  258]\n",
      "Test Error: Avg loss: 691217.347222 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 42515208.000000  [   10/  258]\n",
      "loss: 33793824.000000  [  110/  258]\n",
      "loss: 44655432.000000  [  210/  258]\n",
      "Test Error: Avg loss: 656253.347222 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 48567876.000000  [   10/  258]\n",
      "loss: 107630368.000000  [  110/  258]\n",
      "loss: 52172580.000000  [  210/  258]\n",
      "Test Error: Avg loss: 610468.538194 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 57374124.000000  [   10/  258]\n",
      "loss: 89524872.000000  [  110/  258]\n",
      "loss: 53336232.000000  [  210/  258]\n",
      "Test Error: Avg loss: 565324.826389 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 23165734.000000  [   10/  258]\n",
      "loss: 41458668.000000  [  110/  258]\n",
      "loss: 39084416.000000  [  210/  258]\n",
      "Test Error: Avg loss: 535915.173611 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 34302604.000000  [   10/  258]\n",
      "loss: 55036628.000000  [  110/  258]\n",
      "loss: 38399160.000000  [  210/  258]\n",
      "Test Error: Avg loss: 478282.732639 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 45591568.000000  [   10/  258]\n",
      "loss: 59585364.000000  [  110/  258]\n",
      "loss: 53274364.000000  [  210/  258]\n",
      "Test Error: Avg loss: 428520.947917 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 41059184.000000  [   10/  258]\n",
      "loss: 31093782.000000  [  110/  258]\n",
      "loss: 26119076.000000  [  210/  258]\n",
      "Test Error: Avg loss: 348563.303819 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 29714212.000000  [   10/  258]\n",
      "loss: 25042212.000000  [  110/  258]\n",
      "loss: 45455404.000000  [  210/  258]\n",
      "Test Error: Avg loss: 312692.663194 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 20799892.000000  [   10/  258]\n",
      "loss: 11214608.000000  [  110/  258]\n",
      "loss: 18773414.000000  [  210/  258]\n",
      "Test Error: Avg loss: 262608.697917 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 23488288.000000  [   10/  258]\n",
      "loss: 15331072.000000  [  110/  258]\n",
      "loss: 30468668.000000  [  210/  258]\n",
      "Test Error: Avg loss: 211512.945312 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 20900948.000000  [   10/  258]\n",
      "loss: 43860048.000000  [  110/  258]\n",
      "loss: 12459429.000000  [  210/  258]\n",
      "Test Error: Avg loss: 165960.414931 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 29588706.000000  [   10/  258]\n",
      "loss: 32340200.000000  [  110/  258]\n",
      "loss: 17309860.000000  [  210/  258]\n",
      "Test Error: Avg loss: 131346.300347 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 21425544.000000  [   10/  258]\n",
      "loss: 15086395.000000  [  110/  258]\n",
      "loss: 9332710.000000  [  210/  258]\n",
      "Test Error: Avg loss: 132735.134549 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 16809886.000000  [   10/  258]\n",
      "loss: 28593798.000000  [  110/  258]\n",
      "loss: 17135262.000000  [  210/  258]\n",
      "Test Error: Avg loss: 130977.055556 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 42080988.000000  [   10/  258]\n",
      "loss: 13501338.000000  [  110/  258]\n",
      "loss: 15649343.000000  [  210/  258]\n",
      "Test Error: Avg loss: 118459.451389 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 12228452.000000  [   10/  258]\n",
      "loss: 31101802.000000  [  110/  258]\n",
      "loss: 19984960.000000  [  210/  258]\n",
      "Test Error: Avg loss: 109474.983507 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 17169746.000000  [   10/  258]\n",
      "loss: 15192604.000000  [  110/  258]\n",
      "loss: 7477402.500000  [  210/  258]\n",
      "Test Error: Avg loss: 94860.094618 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 7716211.500000  [   10/  258]\n",
      "loss: 23285614.000000  [  110/  258]\n",
      "loss: 11322569.000000  [  210/  258]\n",
      "Test Error: Avg loss: 85181.358073 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 25457272.000000  [   10/  258]\n",
      "loss: 22353276.000000  [  110/  258]\n",
      "loss: 13290364.000000  [  210/  258]\n",
      "Test Error: Avg loss: 63023.275174 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 24309122.000000  [   10/  258]\n",
      "loss: 10648697.000000  [  110/  258]\n",
      "loss: 17694908.000000  [  210/  258]\n",
      "Test Error: Avg loss: 51721.019097 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 7217611.000000  [   10/  258]\n",
      "loss: 13027799.000000  [  110/  258]\n",
      "loss: 12739678.000000  [  210/  258]\n",
      "Test Error: Avg loss: 39361.237847 \n",
      "\n",
      "Test Error: Avg loss: 39361.237847 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 645849216.000000  [   10/  258]\n",
      "loss: 451718720.000000  [  110/  258]\n",
      "loss: 222610928.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1401453.750000 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 226052192.000000  [   10/  258]\n",
      "loss: 163376288.000000  [  110/  258]\n",
      "loss: 206429600.000000  [  210/  258]\n",
      "Test Error: Avg loss: 660792.236111 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 133666432.000000  [   10/  258]\n",
      "loss: 120030216.000000  [  110/  258]\n",
      "loss: 109924720.000000  [  210/  258]\n",
      "Test Error: Avg loss: 548096.944444 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 76821840.000000  [   10/  258]\n",
      "loss: 60475720.000000  [  110/  258]\n",
      "loss: 101830784.000000  [  210/  258]\n",
      "Test Error: Avg loss: 411181.288194 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 115237088.000000  [   10/  258]\n",
      "loss: 87704288.000000  [  110/  258]\n",
      "loss: 147866832.000000  [  210/  258]\n",
      "Test Error: Avg loss: 314255.118056 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 68041216.000000  [   10/  258]\n",
      "loss: 174372160.000000  [  110/  258]\n",
      "loss: 129846840.000000  [  210/  258]\n",
      "Test Error: Avg loss: 270368.668403 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 75254864.000000  [   10/  258]\n",
      "loss: 183183744.000000  [  110/  258]\n",
      "loss: 117210016.000000  [  210/  258]\n",
      "Test Error: Avg loss: 232232.651042 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 116584416.000000  [   10/  258]\n",
      "loss: 149385552.000000  [  110/  258]\n",
      "loss: 33959688.000000  [  210/  258]\n",
      "Test Error: Avg loss: 271569.788194 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 63422380.000000  [   10/  258]\n",
      "loss: 59414368.000000  [  110/  258]\n",
      "loss: 20523104.000000  [  210/  258]\n",
      "Test Error: Avg loss: 223746.262153 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 44005048.000000  [   10/  258]\n",
      "loss: 55551464.000000  [  110/  258]\n",
      "loss: 55146464.000000  [  210/  258]\n",
      "Test Error: Avg loss: 193427.680556 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 140488944.000000  [   10/  258]\n",
      "loss: 64468776.000000  [  110/  258]\n",
      "loss: 51371640.000000  [  210/  258]\n",
      "Test Error: Avg loss: 168763.723958 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 42816416.000000  [   10/  258]\n",
      "loss: 49609872.000000  [  110/  258]\n",
      "loss: 57656516.000000  [  210/  258]\n",
      "Test Error: Avg loss: 142444.736111 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 74888496.000000  [   10/  258]\n",
      "loss: 41986788.000000  [  110/  258]\n",
      "loss: 28621800.000000  [  210/  258]\n",
      "Test Error: Avg loss: 138594.589410 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 64687104.000000  [   10/  258]\n",
      "loss: 54723768.000000  [  110/  258]\n",
      "loss: 19159964.000000  [  210/  258]\n",
      "Test Error: Avg loss: 124884.504340 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 41340972.000000  [   10/  258]\n",
      "loss: 34268824.000000  [  110/  258]\n",
      "loss: 28231840.000000  [  210/  258]\n",
      "Test Error: Avg loss: 110085.690104 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 21683920.000000  [   10/  258]\n",
      "loss: 33103930.000000  [  110/  258]\n",
      "loss: 16220801.000000  [  210/  258]\n",
      "Test Error: Avg loss: 76473.663628 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 26239482.000000  [   10/  258]\n",
      "loss: 34667796.000000  [  110/  258]\n",
      "loss: 27871430.000000  [  210/  258]\n",
      "Test Error: Avg loss: 51463.368707 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 20017904.000000  [   10/  258]\n",
      "loss: 32647984.000000  [  110/  258]\n",
      "loss: 19941662.000000  [  210/  258]\n",
      "Test Error: Avg loss: 30976.214084 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 35765248.000000  [   10/  258]\n",
      "loss: 20248772.000000  [  110/  258]\n",
      "loss: 30143084.000000  [  210/  258]\n",
      "Test Error: Avg loss: 34948.603299 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 27752004.000000  [   10/  258]\n",
      "loss: 44742296.000000  [  110/  258]\n",
      "loss: 15563091.000000  [  210/  258]\n",
      "Test Error: Avg loss: 27183.170546 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 12044623.000000  [   10/  258]\n",
      "loss: 26369792.000000  [  110/  258]\n",
      "loss: 19597292.000000  [  210/  258]\n",
      "Test Error: Avg loss: 19068.936496 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 14171555.000000  [   10/  258]\n",
      "loss: 33510462.000000  [  110/  258]\n",
      "loss: 17008282.000000  [  210/  258]\n",
      "Test Error: Avg loss: 15490.329115 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 25153468.000000  [   10/  258]\n",
      "loss: 28228290.000000  [  110/  258]\n",
      "loss: 23816400.000000  [  210/  258]\n",
      "Test Error: Avg loss: 7309.162571 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 20184156.000000  [   10/  258]\n",
      "loss: 9700974.000000  [  110/  258]\n",
      "loss: 14127899.000000  [  210/  258]\n",
      "Test Error: Avg loss: 4976.600260 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 32708880.000000  [   10/  258]\n",
      "loss: 13203360.000000  [  110/  258]\n",
      "loss: 19579304.000000  [  210/  258]\n",
      "Test Error: Avg loss: 6575.885145 \n",
      "\n",
      "Test Error: Avg loss: 6575.885145 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1022281600.000000  [   10/  258]\n",
      "loss: 1112312320.000000  [  110/  258]\n",
      "loss: 916484672.000000  [  210/  258]\n",
      "Test Error: Avg loss: 7267734.722222 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 469584928.000000  [   10/  258]\n",
      "loss: 347163584.000000  [  110/  258]\n",
      "loss: 261177904.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2970849.666667 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 480684352.000000  [   10/  258]\n",
      "loss: 407038816.000000  [  110/  258]\n",
      "loss: 178313936.000000  [  210/  258]\n",
      "Test Error: Avg loss: 2014764.500000 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 252841184.000000  [   10/  258]\n",
      "loss: 156501024.000000  [  110/  258]\n",
      "loss: 196868320.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1740056.805556 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 232942624.000000  [   10/  258]\n",
      "loss: 240915584.000000  [  110/  258]\n",
      "loss: 157063808.000000  [  210/  258]\n",
      "Test Error: Avg loss: 1329365.902778 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 178343440.000000  [   10/  258]\n",
      "loss: 111916816.000000  [  110/  258]\n",
      "loss: 216238208.000000  [  210/  258]\n",
      "Test Error: Avg loss: 914315.326389 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 250125568.000000  [   10/  258]\n",
      "loss: 121061392.000000  [  110/  258]\n",
      "loss: 174522608.000000  [  210/  258]\n",
      "Test Error: Avg loss: 571403.055556 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 156974336.000000  [   10/  258]\n",
      "loss: 115344048.000000  [  110/  258]\n",
      "loss: 62110048.000000  [  210/  258]\n",
      "Test Error: Avg loss: 436029.458333 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 174464304.000000  [   10/  258]\n",
      "loss: 148356560.000000  [  110/  258]\n",
      "loss: 153397216.000000  [  210/  258]\n",
      "Test Error: Avg loss: 406550.687500 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 109903456.000000  [   10/  258]\n",
      "loss: 102394640.000000  [  110/  258]\n",
      "loss: 65319696.000000  [  210/  258]\n",
      "Test Error: Avg loss: 301287.033854 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 93085920.000000  [   10/  258]\n",
      "loss: 165228352.000000  [  110/  258]\n",
      "loss: 129466120.000000  [  210/  258]\n",
      "Test Error: Avg loss: 286711.755208 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 119199024.000000  [   10/  258]\n",
      "loss: 81077416.000000  [  110/  258]\n",
      "loss: 27447086.000000  [  210/  258]\n",
      "Test Error: Avg loss: 199086.533854 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 63418248.000000  [   10/  258]\n",
      "loss: 117663680.000000  [  110/  258]\n",
      "loss: 86129176.000000  [  210/  258]\n",
      "Test Error: Avg loss: 198836.458333 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 101149968.000000  [   10/  258]\n",
      "loss: 77484824.000000  [  110/  258]\n",
      "loss: 79012856.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181062.307292 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 71545512.000000  [   10/  258]\n",
      "loss: 93771464.000000  [  110/  258]\n",
      "loss: 23234748.000000  [  210/  258]\n",
      "Test Error: Avg loss: 185535.253472 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 95478536.000000  [   10/  258]\n",
      "loss: 44710280.000000  [  110/  258]\n",
      "loss: 61047988.000000  [  210/  258]\n",
      "Test Error: Avg loss: 173053.885417 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 27906606.000000  [   10/  258]\n",
      "loss: 59108336.000000  [  110/  258]\n",
      "loss: 24684264.000000  [  210/  258]\n",
      "Test Error: Avg loss: 129983.180556 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 50832716.000000  [   10/  258]\n",
      "loss: 84213480.000000  [  110/  258]\n",
      "loss: 59656852.000000  [  210/  258]\n",
      "Test Error: Avg loss: 177301.791667 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 45300984.000000  [   10/  258]\n",
      "loss: 70237168.000000  [  110/  258]\n",
      "loss: 67129312.000000  [  210/  258]\n",
      "Test Error: Avg loss: 181653.630208 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 53607024.000000  [   10/  258]\n",
      "loss: 44813828.000000  [  110/  258]\n",
      "loss: 55365180.000000  [  210/  258]\n",
      "Test Error: Avg loss: 133846.065104 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 34110096.000000  [   10/  258]\n",
      "loss: 56501880.000000  [  110/  258]\n",
      "loss: 38995944.000000  [  210/  258]\n",
      "Test Error: Avg loss: 129086.535590 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 78672424.000000  [   10/  258]\n",
      "loss: 52146260.000000  [  110/  258]\n",
      "loss: 38439584.000000  [  210/  258]\n",
      "Test Error: Avg loss: 84411.441406 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 33738500.000000  [   10/  258]\n",
      "loss: 45890056.000000  [  110/  258]\n",
      "loss: 18147250.000000  [  210/  258]\n",
      "Test Error: Avg loss: 85056.932292 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 25371348.000000  [   10/  258]\n",
      "loss: 25404656.000000  [  110/  258]\n",
      "loss: 36897908.000000  [  210/  258]\n",
      "Test Error: Avg loss: 127420.418403 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 20944352.000000  [   10/  258]\n",
      "loss: 18934624.000000  [  110/  258]\n",
      "loss: 44119296.000000  [  210/  258]\n",
      "Test Error: Avg loss: 116502.782986 \n",
      "\n",
      "Test Error: Avg loss: 116502.782986 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for chunk in range(len(train_data_chunked)):\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_data_chunked[chunk], batch_size=parameters.batch_size)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_data_chunked[chunk], batch_size=parameters.batch_size)\n",
    "\n",
    "    input_dim = train_data_chunked[chunk].get_feature_dim()\n",
    "\n",
    "    deep_gravity_model = DeepGravity(dim_input = input_dim,\n",
    "                                    dim_hidden = parameters.dim_hidden)\n",
    "    \n",
    "    optimizer = optim.RMSprop(deep_gravity_model.parameters(), lr=parameters.lr, momentum=parameters.momentum)\n",
    "\n",
    "    for t in range(parameters.epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        model_utils.train(train_data_loader, deep_gravity_model, optimizer)\n",
    "        model_utils.test(test_data_loader, deep_gravity_model, test_data_chunked[chunk], loss_fn = None)\n",
    "\n",
    "    model_utils.test(test_data_loader, deep_gravity_model, test_data_chunked[chunk], loss_fn = None, store_predictions=True)\n",
    "    prediction_list.append(test_data_chunked[chunk].compile_predictions(columns_to_rename = parameters.columns_to_rename))\n",
    "    print(\"Done!\")\n",
    "pd.concat(prediction_list, axis=0).to_csv(f\"{parameters.output_path}/prediction_{str(datetime.datetime.now()).replace(' ', '_')[:19]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([i[1] for i in train_data_chunked[0].data_dict.keys()])\n",
    "#train_data_chunked[0].data_dict[(32, 1996)].columns\n",
    "#data_loader = torch.utils.data.DataLoader(flow_data_chunked[0], batch_size=parameters.batch_size)\n",
    "#for X, y in data_loader:\n",
    "#    print(f\"Shape of X : {X.shape}\")\n",
    "#    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac1c141dd677d21aa3d7e112522370869da97ef62e316f915c40dc907532f18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
