{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook runs the Deep Gravity model on the yearly trade prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "import random\n",
    "import torch.utils.data.distributed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from ray import air, tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from functools import partial\n",
    "\n",
    "import model_utils\n",
    "from data_compiler import FlowDataset\n",
    "from deepgravity import DeepGravity\n",
    "\n",
    "sys.path.append('../trade_predictions')\n",
    "import parameters\n",
    "\n",
    "# random seeds\n",
    "torch.manual_seed(parameters.seed)\n",
    "np.random.seed(parameters.seed)\n",
    "random.seed(parameters.seed)\n",
    "\n",
    "torch_device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:13<00:00,  3.70s/it]\n",
      "100%|██████████| 20/20 [00:55<00:00,  2.79s/it]\n",
      "100%|██████████| 20/20 [00:00<00:00, 456.99it/s]\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Load data\n",
    "##############\n",
    "\n",
    "nodes = pd.read_csv(parameters.node_path)\n",
    "nodes_columns = parameters.node_features + [parameters.node_id] + [parameters.node_timestamp]\n",
    "nodes = nodes[nodes_columns]\n",
    "\n",
    "edges = pd.read_csv(parameters.edge_path)\n",
    "edges_columns = parameters.flows_features + [parameters.flow_origin] + \\\n",
    "    [parameters.flow_destination] + [parameters.flows_timestamp] + \\\n",
    "        [parameters.flows_value]\n",
    "edges = edges[edges_columns]\n",
    "\n",
    "##############\n",
    "# Initial cleaning\n",
    "##############\n",
    "\n",
    "nodes = nodes.fillna(0)\n",
    "\n",
    "##############\n",
    "# Create data objects\n",
    "##############\n",
    "\n",
    "columns = {'node_id': parameters.node_id,\n",
    "           'node_timestamp': parameters.node_timestamp,\n",
    "           'flow_origin': parameters.flow_origin,\n",
    "           'flow_destination': parameters.flow_destination,\n",
    "           'flows_timestamp': parameters.flows_timestamp,\n",
    "           'flows_value':parameters.flows_value}\n",
    "\n",
    "flow_data = FlowDataset(columns=columns,\n",
    "                        unit = [parameters.flow_origin, parameters.flows_timestamp],\n",
    "                        nodes=nodes,\n",
    "                        edges=edges,)\n",
    "\n",
    "# Create a list of FlowDataset objects\n",
    "flow_data_chunked = flow_data.create_chunks(chunk_size=6)\n",
    "\n",
    "# Add past values to each chunk\n",
    "[flow_chunk.add_past_values(periods=parameters.lag_periods,\n",
    "                            edge_columns = parameters.time_dependent_edge_columns,\n",
    "                            node_columns = parameters.time_dependent_node_columns) for flow_chunk in tqdm.tqdm(flow_data_chunked)]\n",
    "\n",
    "# Add target to each chunk\n",
    "[flow_chunk.add_target_values() for flow_chunk in tqdm.tqdm(flow_data_chunked)]\n",
    "\n",
    "# Create a list of FlowDataset objects\n",
    "train_data_chunked = []\n",
    "validation_data_chunked = []\n",
    "test_data_chunked = []\n",
    "\n",
    "for flow_data in tqdm.tqdm(flow_data_chunked):\n",
    "    train_data, validation_data, test_data = flow_data.split_train_validate_test(validation_period = 1)\n",
    "    train_data_chunked.append(train_data)\n",
    "    validation_data_chunked.append(validation_data)\n",
    "    test_data_chunked.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-08 18:23:35 (running for 00:00:00.11)\n",
      "Memory usage on this node: 5.7/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "| Trial name                                 | status   | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |\n",
      "|--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------|\n",
      "| train_and_validate_deepgravity_b5d43_00000 | RUNNING  | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 |\n",
      "| train_and_validate_deepgravity_b5d43_00001 | PENDING  |                 |            4 |           32 |        0.45 | 0.0112302 |           15 |\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-04-08 18:23:55 (running for 00:00:20.02)\n",
      "Memory usage on this node: 6.1/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "| Trial name                                 | status   | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |\n",
      "|--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------|\n",
      "| train_and_validate_deepgravity_b5d43_00000 | RUNNING  | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 |\n",
      "| train_and_validate_deepgravity_b5d43_00001 | PENDING  |                 |            4 |           32 |        0.45 | 0.0112302 |           15 |\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-04-08 18:24:00 (running for 00:00:25.14)\n",
      "Memory usage on this node: 6.2/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "| Trial name                                 | status   | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |\n",
      "|--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------|\n",
      "| train_and_validate_deepgravity_b5d43_00000 | RUNNING  | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 |\n",
      "| train_and_validate_deepgravity_b5d43_00001 | PENDING  |                 |            4 |           32 |        0.45 | 0.0112302 |           15 |\n",
      "+--------------------------------------------+----------+-----------------+--------------+--------------+-------------+-----------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                                       </th><th>hostname                 </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">       loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_validate_deepgravity_b5d43_00000</td><td>2023-04-08_18-24-04</td><td>True  </td><td>                </td><td>e50e7a39776d43dbb1d430181d3cb72d</td><td>0_batch_size=8,dim_hidden=16,dropout_p=0.4500,lr=0.0749,num_layers=5 </td><td>Gyorgys-MacBook-Pro.local</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">1.31703e+17</td><td>127.0.0.1</td><td style=\"text-align: right;\">22294</td><td>True               </td><td style=\"text-align: right;\">             14.0685</td><td style=\"text-align: right;\">          3.17818 </td><td style=\"text-align: right;\">       14.0685</td><td style=\"text-align: right;\"> 1680971044</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>b5d43_00000</td><td style=\"text-align: right;\">    0.0116789</td></tr>\n",
       "<tr><td>train_and_validate_deepgravity_b5d43_00001</td><td>2023-04-08_18-24-19</td><td>True  </td><td>                </td><td>e50e7a39776d43dbb1d430181d3cb72d</td><td>1_batch_size=4,dim_hidden=32,dropout_p=0.4500,lr=0.0112,num_layers=15</td><td>Gyorgys-MacBook-Pro.local</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">4.32091e+13</td><td>127.0.0.1</td><td style=\"text-align: right;\">22294</td><td>True               </td><td style=\"text-align: right;\">             14.8015</td><td style=\"text-align: right;\">          0.916771</td><td style=\"text-align: right;\">       14.8015</td><td style=\"text-align: right;\"> 1680971059</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>b5d43_00001</td><td style=\"text-align: right;\">    0.0116789</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate_deepgravity pid=22294)\u001b[0m Finished training!\n",
      "== Status ==\n",
      "Current time: 2023-04-08 18:24:09 (running for 00:00:34.81)\n",
      "Memory usage on this node: 6.2/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.3170295056000614e+17 | Iter 1.000: -4.0227602027554703e+18\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "| Trial name                                 | status     | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |        loss |   training_iteration |\n",
      "|--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------|\n",
      "| train_and_validate_deepgravity_b5d43_00001 | RUNNING    | 127.0.0.1:22294 |            4 |           32 |        0.45 | 0.0112302 |           15 |             |                      |\n",
      "| train_and_validate_deepgravity_b5d43_00000 | TERMINATED | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 | 1.31703e+17 |                    2 |\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-04-08 18:24:14 (running for 00:00:39.84)\n",
      "Memory usage on this node: 6.0/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.3170295056000614e+17 | Iter 1.000: -4.0227602027554703e+18\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "| Trial name                                 | status     | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |        loss |   training_iteration |\n",
      "|--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------|\n",
      "| train_and_validate_deepgravity_b5d43_00001 | RUNNING    | 127.0.0.1:22294 |            4 |           32 |        0.45 | 0.0112302 |           15 |             |                      |\n",
      "| train_and_validate_deepgravity_b5d43_00000 | TERMINATED | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 | 1.31703e+17 |                    2 |\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate_deepgravity pid=22294)\u001b[0m Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:24:19,700\tINFO tune.py:798 -- Total run time: 44.61 seconds (44.57 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-08 18:24:19 (running for 00:00:44.59)\n",
      "Memory usage on this node: 5.6/8.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -6.587307983691627e+16 | Iter 1.000: -2.0114376190430828e+18\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.65 GiB heap, 0.0/1.33 GiB objects\n",
      "Result logdir: /Users/rgyuri/ray_results/train_and_validate_deepgravity_2023-04-08_18-23-35\n",
      "Number of trials: 2/2 (2 TERMINATED)\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "| Trial name                                 | status     | loc             |   batch_size |   dim_hidden |   dropout_p |        lr |   num_layers |        loss |   training_iteration |\n",
      "|--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------|\n",
      "| train_and_validate_deepgravity_b5d43_00000 | TERMINATED | 127.0.0.1:22294 |            8 |           16 |        0.45 | 0.074889  |            5 | 1.31703e+17 |                    2 |\n",
      "| train_and_validate_deepgravity_b5d43_00001 | TERMINATED | 127.0.0.1:22294 |            4 |           32 |        0.45 | 0.0112302 |           15 | 4.32091e+13 |                    2 |\n",
      "+--------------------------------------------+------------+-----------------+--------------+--------------+-------------+-----------+--------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 0.01123023399834925, 'batch_size': 4, 'dim_hidden': 32, 'dropout_p': 0.45, 'num_layers': 15}\n",
      "Best trial final validation loss: 43209113826397.09\n",
      "Test Error: Avg loss: 72011305117882.187500 \n",
      "\n",
      "Finished prediction on test set\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for chunk in range(len(train_data_chunked[:1])):\n",
    "    # Set config where parameters are tuned\n",
    "    config = {\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16]),\n",
    "        \"dim_hidden\": tune.sample_from(lambda _: 2**np.random.randint(2, 6)),\n",
    "        \"dropout_p\": tune.choice([0.25, 0.35, 0.45]),\n",
    "        \"num_layers\": tune.choice([5, 10, 15]),\n",
    "    }\n",
    "    # Set scheduler\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=parameters.epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    # Set reporter\n",
    "    reporter = CLIReporter(\n",
    "            # parameter_columns=[\"lr\", \"batch_size\", \"dim_hidden\", \"dropout_p\", \"num_layers\"],\n",
    "            metric_columns=[\"loss\", \"training_iteration\"])\n",
    "    # Run tuning\n",
    "    result = tune.run(\n",
    "        tune.with_parameters(model_utils.train_and_validate_deepgravity, train_data_chunked = train_data_chunked,\n",
    "                validation_data_chunked = validation_data_chunked, chunk = chunk),\n",
    "        resources_per_trial={\"cpu\": 4},\n",
    "        config=config,\n",
    "        num_samples=10,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "\n",
    "    input_dim = train_data_chunked[chunk].get_feature_dim()\n",
    "    best_trained_model = DeepGravity(dim_input = input_dim,\n",
    "                                    dim_hidden = best_trial.config[\"dim_hidden\"],\n",
    "                                    dropout_p = best_trial.config[\"dropout_p\"],\n",
    "                                    num_layers = best_trial.config[\"num_layers\"],)\n",
    "\n",
    "    best_checkpoint = result.get_best_checkpoint(trial=best_trial, metric=\"loss\", mode=\"min\")\n",
    "    best_checkpoint_dir = best_checkpoint.to_directory(path=os.path.join(parameters.output_path, \"best_checkpoints\", \"trade\", str(chunk)))\n",
    "    model_state, optimizer_state = torch.load(os.path.join(best_checkpoint_dir, f\"checkpoint_{str(datetime.datetime.now()).replace(' ', '_')[:19]}\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_data_chunked[chunk], batch_size=4)\n",
    "    model_utils.test(test_data_loader, best_trained_model, test_data_chunked[chunk], loss_fn = None, store_predictions=True)\n",
    "    print(\"Finished prediction on test set\")\n",
    "    prediction_list.append(test_data_chunked[chunk].compile_predictions(columns_to_rename = parameters.columns_to_rename))\n",
    "#pd.concat(prediction_list, axis=0).to_csv(f\"{parameters.output_path}/prediction_{str(datetime.datetime.now()).replace(' ', '_')[:19]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([i[1] for i in train_data_chunked[0].data_dict.keys()])\n",
    "#train_data_chunked[0].data_dict[(32, 1996)].columns\n",
    "#data_loader = torch.utils.data.DataLoader(flow_data_chunked[0], batch_size=parameters.batch_size)\n",
    "#for X, y in data_loader:\n",
    "#    print(f\"Shape of X : {X.shape}\")\n",
    "#    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac1c141dd677d21aa3d7e112522370869da97ef62e316f915c40dc907532f18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
