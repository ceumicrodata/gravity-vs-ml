{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal.signal import (\n",
    "    temporal_signal_split,\n",
    "    StaticGraphTemporalSignal,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process email network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://snap.stanford.edu/data/email-Eu-core-temporal-Dept1.txt.gz', compression='gzip', delim_whitespace=True, header=None, names=['source', 'target','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp is in seconds. Generate day.\n",
    "df['day'] = df.timestamp//(60*60*24)\n",
    "\n",
    "# Drop last (not full) day as it is not representative\n",
    "df = df[df.day!=df.day.max()]\n",
    "\n",
    "# Aggregate to daily number of emails to have edge weights\n",
    "aggregates = df.groupby([x for x in list(df) if x!='timestamp']).count().reset_index().rename(columns={'timestamp':'weight'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create node indices\n",
    "translator = dict(zip(a:=pd.concat([aggregates.source, aggregates.target]).unique(), range(len(a))))\n",
    "aggregates['id_source'] = aggregates.source.map(lambda x: translator[x])\n",
    "aggregates['id_target'] = aggregates.target.map(lambda x: translator[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network\n",
    "network = nx.from_pandas_edgelist(aggregates, source='id_source', target='id_target', edge_attr='weight', create_using=nx.DiGraph)\n",
    "\n",
    "# Transform to line graph\n",
    "line_graph = nx.line_graph(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final node indices\n",
    "line_node_list = list(line_graph.nodes())\n",
    "line_translator = dict(zip(a:=list(set(line_node_list)), range(len(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge list and edge weights\n",
    "# Edge weights are average number of emails of connecting node\n",
    "\n",
    "edges = [[],[]]\n",
    "edge_weights = []\n",
    "for source, target in list(line_graph.edges):\n",
    "    edges[0].append(line_translator[source])\n",
    "    edges[1].append(line_translator[target])\n",
    "    edge_weights.append(aggregates[((aggregates.id_source==source[1])|(aggregates.id_target==source[1]))].weight.mean())\n",
    "\n",
    "edges = np.array(edges)\n",
    "edge_weights = np.array(edge_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate target arrays\n",
    "numdays = aggregates.day.nunique()\n",
    "aggregates = aggregates.set_index(['id_source', 'id_target', 'day'])\n",
    "line_retranslator = {k:v for v, k in line_translator.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for day in range(numdays):\n",
    "    daily_targets = []\n",
    "    for node in range(len(line_node_list)):\n",
    "        source, target = line_retranslator[node]\n",
    "        try:\n",
    "            daily_targets.append(aggregates.loc[(source, target, day)].weight)\n",
    "        except KeyError:\n",
    "            daily_targets.append(0)\n",
    "    targets.append(daily_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features (messages in last 10 days)\n",
    "feat_num = 10\n",
    "features = []\n",
    "\n",
    "for day in range(numdays-feat_num):\n",
    "    daily_features = []\n",
    "    for node in range(len(line_node_list)):\n",
    "        node_feat = []\n",
    "        for feature_i in range(feat_num):\n",
    "            node_feat.append(targets[day+feature_i][node])\n",
    "        daily_features.append(node_feat)\n",
    "    features.append(daily_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To array\n",
    "targets = np.array(targets[feat_num:])\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data iterator\n",
    "data = StaticGraphTemporalSignal(edges, edge_weights, features, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dcrnn model\n",
    "\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    \"\"\"Class for a pytorch neural network module\"\"\"\n",
    "\n",
    "    def __init__(self, node_features: int, out_channels: int, filter_size: int):\n",
    "        \"\"\"\n",
    "        Initialize a pytorch model with DCRNN architecture\n",
    "\n",
    "        Args:\n",
    "            node_features:\n",
    "            Number of node features to use.\n",
    "            out_channels:\n",
    "            Number of DCRNN hidden features.\n",
    "            filter_size:\n",
    "            DCRNN filter size.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.recurrent = DCRNN(node_features, out_channels, filter_size)\n",
    "        self.linear = torch.nn.Linear(out_channels, filter_size)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Perform a forward feed\n",
    "        Args:\n",
    "            x:\n",
    "            feature Pytorch Float Tensor\n",
    "            edge_index:\n",
    "            Pytorch Float Tensor of edge indices\n",
    "            edge_weight:\n",
    "            Pytorch Float Tensor of edge weights\n",
    "\n",
    "        Returns:\n",
    "            tens:\n",
    "            Pytorch Float Tensor of Hidden state matrix for all nodes\n",
    "        \"\"\"\n",
    "        tens = self.recurrent(x, edge_index, edge_weight)\n",
    "        tens = F.relu(tens)\n",
    "        tens = self.linear(tens)\n",
    "        return tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model\n",
    "model = RecurrentGCN(10, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization with temporal backpropagation: 100%|██████████| 20/20 [10:57<00:00, 32.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# train with adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "model.train()\n",
    "\n",
    "for _ in tqdm(range(20), \"Optimization with temporal backpropagation\"):\n",
    "    cost = 0\n",
    "    datapoints = 0\n",
    "    for _, snapshot in enumerate(data):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat - snapshot.y) ** 2)\n",
    "        datapoints += 1\n",
    "    cost = cost / (datapoints)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post mortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "yhats = []\n",
    "for _, snapshot in enumerate(data):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        yhats.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2744],\n",
       "        [-0.2744],\n",
       "        [-0.2744],\n",
       "        ...,\n",
       "        [-0.4697],\n",
       "        [-0.4911],\n",
       "        [-0.2744]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first period prediction\n",
    "yhats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first period fact\n",
    "enumerate(data).__next__()[1].y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gnn_chapter-7ZaAeTXn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e236d32e08e81f213d24544f3b539cfd697b78c2f69d9e99900d1c694707da54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
