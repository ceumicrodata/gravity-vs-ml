{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal.signal import (\n",
    "    temporal_signal_split,\n",
    "    StaticGraphTemporalSignal,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/trade_data.csv')[['From', 'To', 'Period', 'Value']]\n",
    "aggregates=df\n",
    "aggregates = aggregates.rename(columns={'From':'source','To':'target','Period':'timestamp'})\n",
    "aggregates['weight'] = (aggregates.Value-aggregates.Value.mean())/aggregates.Value.std()\n",
    "# create node indices\n",
    "translator = dict(zip(a:=pd.concat([aggregates.source, aggregates.target]).unique(), range(len(a))))\n",
    "aggregates['id_source'] = aggregates.source.map(lambda x: translator[x])\n",
    "aggregates['id_target'] = aggregates.target.map(lambda x: translator[x])\n",
    "# Generate network\n",
    "network = nx.from_pandas_edgelist(aggregates, source='id_source', target='id_target', edge_attr='weight', create_using=nx.DiGraph)\n",
    "\n",
    "# Transform to line graph\n",
    "line_graph = nx.line_graph(network)\n",
    "# create final node indices\n",
    "line_node_list = list(line_graph.nodes())\n",
    "line_translator = dict(zip(a:=list(set(line_node_list)), range(len(a))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222157/222157 [04:10<00:00, 888.62it/s] \n"
     ]
    }
   ],
   "source": [
    "# Create edge list and edge weights\n",
    "# Edge weights are average number of emails of connecting node\n",
    "\n",
    "edges = [[],[]]\n",
    "edge_weights = []\n",
    "for source, target in tqdm(list(line_graph.edges)):\n",
    "    edges[0].append(line_translator[source])\n",
    "    edges[1].append(line_translator[target])\n",
    "    edge_weights.append(aggregates[((aggregates.id_source==source[1])|(aggregates.id_target==source[1]))].weight.mean())\n",
    "\n",
    "edges = np.array(edges)\n",
    "edge_weights = np.array(edge_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:22<00:00,  5.40it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 120.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate target arrays\n",
    "numyears = aggregates.timestamp.nunique()\n",
    "years = sorted(aggregates.timestamp.unique().tolist())\n",
    "aggregates = aggregates.set_index(['id_source', 'id_target', 'timestamp'])\n",
    "line_retranslator = {k:v for v, k in line_translator.items()}\n",
    "\n",
    "targets = []\n",
    "for year in tqdm(years):\n",
    "    daily_targets = []\n",
    "    for node in range(len(line_node_list)):\n",
    "        source, target = line_retranslator[node]\n",
    "        try:\n",
    "            daily_targets.append(aggregates.loc[(source, target, year)].weight)\n",
    "        except KeyError:\n",
    "            daily_targets.append(0)\n",
    "    targets.append(daily_targets)\n",
    "\n",
    "# Generate features (trade in last 12 months)\n",
    "feat_num = 12\n",
    "features = []\n",
    "\n",
    "for year in tqdm(range(numyears-feat_num)):\n",
    "    daily_features = []\n",
    "    for node in range(len(line_node_list)):\n",
    "        node_feat = []\n",
    "        for feature_i in range(feat_num):\n",
    "            node_feat.append(targets[year+feature_i][node])\n",
    "        daily_features.append(node_feat)\n",
    "    features.append(daily_features)\n",
    "\n",
    "# To array\n",
    "targets = np.array(targets[feat_num:])\n",
    "features = np.array(features)\n",
    "\n",
    "# Create data iterator\n",
    "data = StaticGraphTemporalSignal(edges, edge_weights, features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open('data.pckl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('alteo-ghi-sim-_r_Z88UJ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "556135bef58bea183c0be3f19805670afe42fd80c5434eb34a78da166f5d6b0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
